{"cells":[{"cell_type":"markdown","metadata":{"id":"m2s4kN_QPQVe"},"source":["# **Dive into Machine Learning: Learning by Implementing**\n","\n","<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/introduction-to-machine-learning.png\" width=\"60%\" />\n","\n","*Before you start*\n","\n","Use this link to access the practical and save a copy.\n","\n","<a href=\"https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Intro_ML_English_Prac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","\n","© Deep Learning Indaba 2023. Apache License 2.0.\n","\n","**Authors: Ulrich A. Mbou Sob, Kale-ab Tessera**\n","\n","**Reviewers: James Allingham, Oumayma Mahjoub, Bunmi Akinremi, Kavengi Kitonga**\n","\n","**Introduction:**\n","\n","In this tutorial, we will explore the fundamentals of machine learning. We will learn how to build and train a machine learning classifier. We will familiarise ourselves with the concepts of loss functions and optimization.\n","\n","**Topics:**\n","\n","Content: Supervised learning, Neural Networks, Numerical Computing\n","\n","Level: <font color='grey'>`Beginner`\n","\n","\n","**Aims/Learning Objectives:**\n","\n","- Understand the basics of machine learning.\n","- Train a linear regression model.\n","- Train a neural network for multi-class classification.\n","\n","**Prerequisites:**\n","\n","- Familiarity with [Numpy](https://numpy.org/doc/stable/user/quickstart.html).\n","\n","**Outline:**\n","\n",">[Dive into Machine Learning: Learning by Implementing](#scrollTo=m2s4kN_QPQVe)\n","\n",">>[What is machine learning](#scrollTo=FVw9C8GugkAj)\n","\n",">>>[1.1 Types of machine learning problems](#scrollTo=v2k8dcYR9Hvb)\n","\n",">>>[1.2 Data](#scrollTo=1KK-dbRw730T)\n","\n",">>[Regression](#scrollTo=e9NW58_3hAg2)\n","\n",">>>[2.1 Linear regression](#scrollTo=bA_2coZvhAg3)\n","\n",">>>>[Loss function and optimization](#scrollTo=hNJgESq_LP4R)\n","\n",">>>>[Training the model using Jax](#scrollTo=q9dQh9DdLYPE)\n","\n",">>>>[Model representation](#scrollTo=XStsgHB2MarI)\n","\n",">>>>[Activation functions](#scrollTo=fkpytbBzMvMj)\n","\n",">>>>[Building a simple neural network model with Jax](#scrollTo=3Wrxt2orM7sk)\n","\n",">>[Classification](#scrollTo=fbTsk0MdhAhC)\n","\n",">>>[3.1 Logistic regression](#scrollTo=wMgxJU0TOX6O)\n","\n",">>>>[Logits and sigmoid activation function](#scrollTo=SE1L3rmaO4UP)\n","\n",">>>>[Extending to Multi-class classification](#scrollTo=HjQNjDC2cG2t)\n","\n",">>>>[Building a simple neural network for classification](#scrollTo=EcXXE56hPOhK)\n","\n",">>>>[Training the model](#scrollTo=GcSvlekHPWxW)\n","\n",">>>>[Evaluating the model](#scrollTo=sGPvmGWkP1fT)\n","\n",">>[Conclusion](#scrollTo=fV3YG7QOZD-B)\n","\n",">>>[Appendix](#scrollTo=742JhcnAxTof)\n","\n",">>>[Basis of JAX [OPTIONAL]](#scrollTo=742JhcnAxTof)\n","\n",">>>[Derivation of partial derivatives for exercise 2 [OPTIONAL]](#scrollTo=kh_8f4gKyufu)\n","\n",">>>[Intuition for multi-class CE loss: exercise 3 [OPTIONAL]](#scrollTo=fRYbQvz01Zlm)\n","\n",">>[Feedback](#scrollTo=o1ndpYE50BpG)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4boGA9rYdt9l"},"outputs":[],"source":["## Install and import anything required. Capture hides the output from the cell.\n","# @title Install and import required packages. (Run Cell)\n","!pip install -q clu\n","\n","import jax\n","import jax.numpy as jnp\n","import flax\n","import flax.linen as nn\n","from typing import NamedTuple, Any, Dict\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from clu import parameter_overview\n","\n","from sklearn.datasets import fetch_openml\n"]},{"cell_type":"markdown","metadata":{"id":"FVw9C8GugkAj"},"source":["## 💻**What is machine learning**\n","In the last two decades, the field of artificial intelligence (AI) has transcended from being mainly used by computer scientists, mathematicians, and physicists to being applied in nearly every domain. Almost every literate human being uses AI in one form or another. Applications like YouTube and Netflix, which we use daily, utilize AI to suggest content that we may like.\n","<center>\n","<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/AIvsML.png\" width=\"80%\"/>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"6pRWdqAi7FTZ"},"source":["AI is the science of developing computer systems capable of performing commonly known tasks that require human intelligence. Machine learning is a subset of AI techniques that learns from data using statistical modelling techniques. Deep Learning is a subset of machine learning that uses artificial neural networks for modelling."]},{"cell_type":"markdown","metadata":{"id":"v2k8dcYR9Hvb"},"source":["### 1.1 Types of machine learning problems\n","\n","Machine learning is based on learning from data. When formulating a machine learning problem, the first question we need to ask ourselves is what type of learning task we have at hand. Broadly speaking, machine learning tasks can be classified into three categories.\n","\n","<center>\n","<img src=\"https://www.researchgate.net/publication/354960266/figure/fig1/AS:1075175843983363@1633353305883/The-main-types-of-machine-learning-Main-approaches-include-classification-and.png\" width=\"80%\" />\n","</center>\n","\n","<font color='red'>Supervised Learning</font>: In supervised learning, the algorithm is provided with a labelled dataset, where each input data point is associated with the correct output (label). The goal is to learn a mapping from inputs to outputs based on the training data so that the model can make accurate predictions on new unseen data.\n","\n","<font color='red'>Unsupervised Learning</font>: In unsupervised learning, the algorithm is given an unlabeled dataset, and the goal is to find patterns, structures, or relationships within the data without labels. The algorithm tries to group similar data points or reduce the dimensionality of the data to reveal underlying structures.\n","\n","<font color='red'>Reinforcement Learning</font>: In reinforcement learning, the algorithm learns to make decisions through interactions with an environment. The learner (agent) receives feedback in the form of rewards or penalties based on its actions, which enables it to learn the best strategy to maximize the cumulative reward over time.\n","\n","**Exercise 1.1**: Can you identify to which of the categories the following task belongs?\n","  - Teaching a robot how to walk.\n","  - Weather prediction.\n","  - Spam email classification.\n","  - Teach a computer how to play chess.\n","  - Grouping together different kinds of movie reviews."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"cLaRGDzv4wR2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707853895063,"user_tz":480,"elapsed":8,"user":{"displayName":"","userId":""}},"outputId":"1ba997a8-ff12-409f-a6d2-937295b166cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Teaching a robot how to walk -- Reinforcement learning\n","Weather prediction -- Supervised learning\n","Spam email classification -- Supervised learning\n","Teach a computer how to play chess -- Reinforcement learning\n","Grouping together different kinds of movie reviews -- Unsupervised learning\n"]}],"source":["# @title Solution - Exercise (Try not to peek until you've given it a good try!')\n","print(\"Teaching a robot how to walk -- Reinforcement learning\")\n","print(\"Weather prediction -- Supervised learning\")\n","print(\"Spam email classification -- Supervised learning\")\n","print(\"Teach a computer how to play chess -- Reinforcement learning\")\n","print(\"Grouping together different kinds of movie reviews -- Unsupervised learning\")"]},{"cell_type":"markdown","metadata":{"id":"1KK-dbRw730T"},"source":["### 1.2 Data\n","\n","> Indented block\n","\n","\n","At the end of this tutorial, we build a digit classifier for the popular mnist digit dataset. This dataset consists of images of handwritten digits. Our task is to build a classifier that predicts the correct digit for each image.\n","\n","Before diving into the different machine learning concepts, let's load the data and visualise a few of the images."]},{"cell_type":"markdown","metadata":{"id":"w8g4rsOy_86b"},"source":["We will use [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html) to load the data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3uN_gxbG2Em","outputId":"1cd6793f-1125-4bbf-9768-2f52f181735e","executionInfo":{"status":"ok","timestamp":1707853901012,"user_tz":480,"elapsed":5954,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Images have shape: (70000, 784), and labels have shape: (70000,)\n","Number of classes is: 10\n","Minimum value in images is: 0\n","Maximum value in images is: 255\n"]}],"source":["# Load the MNIST digits dataset\n","mnist = fetch_openml(name='mnist_784', version=1, as_frame=False, parser='auto')\n","# Extract the data and labels\n","images, labels = mnist.data, mnist.target\n","\n","# Convert labels to integers (they are originally stored as strings)\n","labels = labels.astype(int)\n","\n","# Print shapes of the data\n","print(f\"Images have shape: {images.shape}, and labels have shape: {labels.shape}\")\n","\n","# Verify that we have 10 classes\n","print(f\"Number of classes is: {len(np.unique(labels))}\")\n","\n","# Print the min and max values of the images\n","print(f\"Minimum value in images is: {np.min(images)}\")\n","print(f\"Maximum value in images is: {np.max(images)}\")"]},{"cell_type":"markdown","metadata":{"id":"bNV9b-6bH45y"},"source":["The dataset consists of 70000 gray scale images. Each image has been flattened to a 1-dimensional array of size 784 from its original 28 x 28 shape. We will use the code in the next cell to randomly select some of the images and display them. Note that each time you run the below cell you will get different images displayed because we randomly sample every time."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":746},"id":"-qXlDhYWH_mW","outputId":"89bf14d0-22f1-4d86-901d-abb6dd93933b","executionInfo":{"status":"ok","timestamp":1707853904328,"user_tz":480,"elapsed":3319,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 24 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# @title Plot images\n","def plot_images(images, labels):\n","  rows = 4\n","  cols = 6\n","  num_images = images.shape[0]\n","\n","  fig, axes = plt.subplots(rows, cols, figsize=(8, 8))\n","\n","  for ir in range(rows):\n","    for ic in range(cols):\n","      sample = np.random.randint(0, num_images)\n","      image = images[sample].reshape(28, 28)\n","      axes[ir, ic].imshow(image, cmap='gray')\n","      axes[ir, ic].axis('off')\n","      axes[ir, ic].set_title(f\"Digit {labels[sample]}\")\n","\n","  plt.tight_layout()\n","  plt.show()\n","\n","plot_images(images, labels)"]},{"cell_type":"markdown","metadata":{"id":"jzHwlZp2WfKM"},"source":["**Excercise:** Run the cell above multiple times and look at the images. Can you identify some images that may be difficult to classify?"]},{"cell_type":"markdown","metadata":{"id":"e9NW58_3hAg2"},"source":["## **Regression**\n","Before we build our digit classifier, we need to first grab some key ML concepts."]},{"cell_type":"markdown","metadata":{"id":"1ME59aXJRwE3"},"source":["The curve below is a plot of some data generated using a Sine function. Most often in science, we have data collected through experiments and we want to find a function that explains the data. In general, we need to find a function that maps some inputs in some dimension to some outputs in another dimension.\n","The process of finding such a function also called **model** is commonly referred to in various fields as **regression**. In machine learning this refers to finding a function that maps a set of numerical values called **features** to another set of numerical values called **labels**.  If the function is linear, the process is referred to as **linear regression**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"kDix480DPCgA","outputId":"148e5b27-3b3e-4d6d-b378-1dc62d0e3613","executionInfo":{"status":"ok","timestamp":1707853904328,"user_tz":480,"elapsed":9,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# @title Helper code to plot a Sine curve\n","amplitude = 2\n","x = np.linspace(0, 2*np.pi, 1000)\n","y = amplitude*np.sin(x) + np.random.randn(1000)*0.1   # Calculate y values using the sine function\n","yfit = amplitude*np.sin(x)\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(x, y, label=\"data\", color='red')\n","plt.plot(x, yfit, label=f'Sine Curve with Amplitude = {amplitude}', color='black')\n","plt.title('Sine Curve')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend()\n","# plt.grid()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bA_2coZvhAg3"},"source":["### 2.1 Linear regression\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GGTQetYgNBda"},"source":["Supposed we have a Dataset, with elements $y$ representing the labels and elements $\\mathbf{x}$ representing the features, our goal is to find a function $f$ that maps the features $\\mathbf{x} \\in \\mathbb{R}^d$ to the target variable $y$:\n","$$ y \\, =\\, f(\\mathbf{x}). $$\n","\n","The linear regression model can be represented mathematically as follows\n","$$ f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b,$$\n","where $\\mathbf{w} \\in \\mathbb{R}^d$. $\\mathbf{w}$ and $b$ are the parameters of the model usually referred to as weights. The term $b$ is commonly referred to as the bias and it can be included in $\\mathbf{w}$ by extending the feature vector $\\mathbf{x}$ with 1.\n","\n","An intuitive way to understand the equations above is to remember the equation of a line $$y \\, = \\, mx + c,$$ with the weights and the bias corresponding to the slope and the intercept, $m$ and $c$ respectively.\n","\n","**Note: for the rest of the tutorial we will use the JAX framework. If you are not familiar with JAX, please first follow the optional section in the Appendix on [JAX](#scrollTo=742JhcnAxTof) before continuing.**"]},{"cell_type":"markdown","metadata":{"id":"1SVA5XSjcfpH"},"source":["Code demonstration: linear model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBe3ytk5WyvD"},"outputs":[],"source":["# Example implementation of a linear function computation.\n","\n","x_key = jax.random.PRNGKey(0)\n","dim = 10\n","x = jax.random.uniform(x_key, (dim,))\n","\n","w_key = jax.random.PRNGKey(1)\n","w = jax.random.uniform(w_key, (dim,))\n","\n","b_key = jax.random.PRNGKey(2)\n","b = jax.random.uniform(b_key, (1,))\n","\n","y = jnp.dot(w,x) + b  # can also be achieved using: y = x @ w + b"]},{"cell_type":"markdown","metadata":{"id":"LH73KxFOdAMK"},"source":["**Code task:**\n","\n","In the above cell, we demonstrated how to compute the output of a linear model for a single example in a dataset. When implementing a machine learning model we want to take advantage of linear algebra techniques and available computing resources to process a batch of data at once.\n","\n","Given datasets $\\mathbf{X}$ with multiple examples stacked in the matrix, write a function that applies a linear model to every example.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Psjm_oQY_b7"},"outputs":[],"source":["# @title Run this to generate the data\n","# store the parameters in a dictionary\n","params = dict(w=w, b=b)\n","\n","batch_size = 5\n","X = jax.random.uniform(x_key, (batch_size, dim))\n","data = jax.random.uniform(x_key, (batch_size,))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qh-eOfEdh-f0"},"outputs":[],"source":["def linear_model(params: Any, X: jnp.ndarray) -> jnp.ndarray:\n","  # complete this code\n","  w = params['w']\n","  b = ... # update me. hint look at the above line for w\n","\n","  # compute m = f(x) here using w,b and X\n","  m = ... # update me.\n","\n","  return m\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iL92mYSlCkM"},"outputs":[],"source":["# @title Run me to test your code\n","\n","def test_linear_model():\n","  assert (linear_model(params, X) == X @ w + b).all()\n","  print(\"Nice! Your answer looks correct.\")\n","\n","test_linear_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"yFR2NtnTKgJK"},"outputs":[],"source":["# @title Solution - linear model (Try not to peek until you've given it a good try!')\n","def linear_model(params: Dict[str, jnp.ndarray], X: jnp.ndarray) -> jnp.ndarray:\n","  # complete this code\n","  w = params['w']\n","  b = params['b']\n","\n","  # compute m = f(x) here using w,b and X\n","  m = X @ w + b\n","\n","  return m"]},{"cell_type":"markdown","metadata":{"id":"hNJgESq_LP4R"},"source":["#### Loss function and optimization\n"]},{"cell_type":"markdown","metadata":{"id":"zV6jTdQN2NvO"},"source":["**Loss function**\n","\n","Whenever we are fitting a model to some data, we need a function to measure how well the model is performing. This function is called the **loss function**. It measures the amount of errors between our model and data."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"HI8NPCQn3gn1"},"outputs":[],"source":["# @title Helper code to plot errors\n","\n","# Set random seed for reproducibility\n","np.random.seed(42)\n","\n","# Number of points to generate\n","num_points = 20\n","\n","# Generate random points and lines\n","points_x = np.random.rand(num_points)\n","slope_random_line = np.random.rand()\n","intercept_random_line = np.random.rand()\n","\n","points_y = slope_random_line*points_x + intercept_random_line + np.random.normal(0, 1, num_points)*0.15\n","\n","# Function to calculate distance from point (x, y) to the line y = mx + b\n","def distance_to_line(x, y, m, b):\n","    return abs(y - m * x - b) / np.sqrt(1 + m**2)\n","\n","# Calculate distances from each point to the random line\n","distances = distance_to_line(points_x, points_y, slope_random_line, intercept_random_line)\n","\n","# Create the scatter plot\n","plt.figure(figsize=(10, 6))\n","\n","# Plot the random line\n","plt.plot(np.sort(points_x), slope_random_line * np.sort(points_x) + intercept_random_line, c='blue', label='Model')\n","\n","# Plot the points\n","plt.scatter(points_x, points_y, c='red', label='Data', marker='o', s=50)\n","\n","# Plot lines from each point to the random line (in different colors)\n","for i in range(num_points):\n","    plt.plot([points_x[i], points_x[i]], [points_y[i], slope_random_line * points_x[i] + intercept_random_line],\n","             c='green', alpha=0.7)\n","\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","plt.title(\"Errors for each data point\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Fj_aG5jG3b8K"},"source":["Consider the figure above with data points in red. If the blue line is our model, then vertical green lines represent the errors we make on each data point. The loss function tries to capture the total error we make for every data point. One loss function we can use in this case is the <font color='red'>mean square error</font> between the predicted and the true values. This is equivalent to summing up all the distances in green. This can be written mathematically as follows:\n","$$ \\mathcal{L}(\\mathbb{θ}) \\, = \\, \\frac{1}{m}∑_{i}({y_i - \\hat{y}_i})^2,$$\n","where $\\mathbb{θ} = [\\mathbf{w}, b]$,  $\\mathcal{L}$ denotes the loss function, $\\hat{y}$ represents the predicited value by the model and $m$ is the total number of datapoints.\n","\n","Inserting the formula for a linear model, we obtain the following equation:\n","\n","$$\\mathcal{L}(\\mathbb{θ}) \\, = \\, \\frac{1}{m}∑_{i}(y_i - \\mathbf{w}^T\\mathbf{x}_i - b)^2. $$\n","\n","<font color='red'>Note: they are different loss functions we could use in this case. You can see some other common loss functions [here](https://www.geeksforgeeks.org/ml-common-loss-functions/).</font>"]},{"cell_type":"markdown","metadata":{"id":"coIwS0_5I-p-"},"source":["**Code task:** Implement the loss function above using the linear model function defined above.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5ji0ISCJWQ3"},"outputs":[],"source":["def loss_fn(params: Dict[str, jnp.array], X: jnp.array, y: jnp.array):\n","  # complete this code\n","\n","  pred = linear_model(params, X)\n","\n","  loss = ... # your code here\n","\n","  return 0"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"O0m0EZVqMUw7"},"outputs":[],"source":["# @title Run to test my code\n","def test_linear_loss_fn():\n","  pred = linear_model(params, X)\n","  loss = jnp.mean((pred-data)**2)\n","  assert loss_fn(params, X, data) == loss\n","  print(\"Nice! Your answer looks correct.\")\n","\n","test_linear_loss_fn()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ehK1Y1pgZ83Y"},"outputs":[],"source":["# @title Sample solution (Try not to peek until you've given it a good try!')\n","def loss_fn(params: Dict[str, jnp.array], X: jnp.array, y: jnp.array):\n","  # complete this code\n","\n","  pred = linear_model(params, X)\n","\n","  loss = jnp.mean((pred-y)**2)\n","\n","  return loss"]},{"cell_type":"markdown","metadata":{"id":"NM7aMj_A75M_"},"source":["**Excercise:** Dicuss in groups how we can find the parameters, $\\mathbb{θ}$."]},{"cell_type":"markdown","metadata":{"id":"7SwSstfO9hml"},"source":["🎯 **What is optimization?**\n","\n","Optimization as the name entails is the process of finding the optimal parameters of the model, i.e. the set of parameters that gives the minimum loss possible. Mathematically this is represented as follows\n","\n","$$\\hat{\\theta} \\,= \\, \\underset{\\mathbf{\\theta}}{\\operatorname{argmin}} \\frac{1}{m}∑_{i}(y_i - \\mathbf{w}^T\\mathbf{x}_i - b)^2.$$"]},{"cell_type":"markdown","metadata":{"id":"kxUMu1HP_D-m"},"source":["<font color='red'> How do we optimise </font>: The figure below is an example plot of the loss at different values of $\\mathbf{w}$ and $b$ for a straight line. The minimum value is indicated with the star. Our goal in optimization is to identify this point.   "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ZjZAVVBK_Fsd"},"outputs":[],"source":["# @title Helper code (to visualise loss landscape)\n","# Define the loss function (Mean Squared Error)\n","from matplotlib.colors import LogNorm\n","\n","def loss_function(y_true, y_pred):\n","    return np.mean((y_true - y_pred) ** 2)\n","\n","# Create a grid of weight (slope) and bias (intercept) values\n","weight_values = np.linspace(-10, 10, 200)\n","bias_values = np.linspace(-10, 10, 200)\n","weight_grid, bias_grid = np.meshgrid(weight_values, bias_values)\n","\n","# Generate random data points for demonstration\n","np.random.seed(0)\n","x = np.linspace(0, 20, 200)\n","y_true = 3 * x + 5 + 0.1 * np.random.normal(0, 1, 200)\n","y_min = 3*x + 5\n","minima = np.array([5, 3])\n","loss_min = loss_function(y_true, y_min)\n","\n","# Compute the loss for each combination of weight and bias values\n","loss_grid = np.zeros_like(weight_grid)\n","for i in range(len(weight_values)):\n","    for j in range(len(bias_values)):\n","        y_pred = weight_values[i] * x + bias_values[j]\n","        loss_grid[i, j] = loss_function(y_true, y_pred)\n","\n","fig = plt.figure(figsize=(8, 5))\n","ax = plt.axes(projection='3d', elev=50, azim=-50)\n","\n","surf = ax.plot_surface(weight_grid, bias_grid, loss_grid, norm=LogNorm(), rstride=1, cstride=1,\n","                edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n","ax.plot(*minima, loss_min, 'r*', markersize=10)\n","\n","ax.set_xlabel('$w$')\n","ax.set_ylabel('$b$')\n","# Remove z-axis ticks and labels\n","ax.set_zticks([])\n","ax.set_zticklabels([])\n","\n","# Add color bar for reference\n","cbar = plt.colorbar(surf, shrink=0.5, aspect=10)\n","cbar.ax.set_ylabel('Loss')\n","\n","# ax.set_xlim((xmin, xmax))\n","# ax.set_ylim((ymin, ymax))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hj1vWUunykNe"},"source":["A **brute force** approach will be to compute the loss function for a large range of possible parameter values and select the parameters with the minimum loss value. While such an approach can work for simple models with 1 or 2 parameters, this is a very tedious approach and the number of possible values to evaluate for large models makes such an approach impractical."]},{"cell_type":"markdown","metadata":{"id":"8h9sZ2vW97-d"},"source":["**Gradient based optimization**\n","\n","The right approach is to use calculus. The derivative of a function is known to be 0 at every turning point (maximum and minimum turning points). Hence to find $\\theta$, which minimises the loss, we need to solve the equation\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta} \\,=\\, 0.$$\n","\n","**Exercise 2:** [OPTIONAL] Can you work out the following expressions for the derivatives of the loss function?\n","\n","$$\\frac{∂ \\mathcal{L}}{\\partial \\mathbf{w}} = \\frac{2}{m}∑_{i}\\mathbf{x}_i(\\mathbf{w}^T\\mathbf{x}_i + b - y_i),$$\n","\n","$$\\frac{∂ \\mathcal{L}}{\\partial b} = \\frac{2}{m}∑_{i}(\\mathbf{w}^T\\mathbf{x}_i + b - y_i).$$\n","\n","Solution here in the [Appendix](#scrollTo=kh_8f4gKyufu)."]},{"cell_type":"markdown","metadata":{"id":"tq4p7ME6GWXO"},"source":["Fortunately, we do not need to compute these analytical expressions or implement them ourselves from scratch. Machine learning frameworks like Jax, [Pytorch](https://pytorch.org/tutorials/) and [Tensorflow](https://www.tensorflow.org/) have highly optimised tools that will compute these for us. In the case of Jax, we can use the function `jax.grad` to compute the derivative of a function with respect to its parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq2SMvz09fW1"},"outputs":[],"source":["# @title Computing derivatives with jax.grad\n","# Computing derviatives with jax\n","\n","def quadratic_fn(x):\n","  return x**2\n","\n","\n","# Compute the derivative of quadratic_fn when x = 1\n","grad_fx =  jax.grad(quadratic_fn)(1.0)\n","assert grad_fx == 2.0\n","print(f\"Gradient of the function x**2 at x = 1 is {grad_fx} as expected.\")"]},{"cell_type":"markdown","metadata":{"id":"LER9QyoXR_ph"},"source":["Importantly Jax computes the derivative in the same way even if our parameters are passed in a different data type such as a dictionary. For example, we can compute the gradient of our loss function above as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfVKXN_ToRcn"},"outputs":[],"source":["# Compute derivatives of the loss_fn with respect to params\n","\n","grads = jax.grad(loss_fn)(params, X, data)\n","print(f\"gradients: {grads}\")"]},{"cell_type":"markdown","metadata":{"id":"zl0_zYWxlGDO"},"source":["Another similar function in Jax is `jax.value_and_grad` which returns both the value of the function and the gradient."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CzKxdMqIlsVk"},"outputs":[],"source":["# Compute derivatives of the loss_fn with respect to params\n","\n","loss, grads = jax.value_and_grad(loss_fn)(params, X, data)\n","print(f\"loss: {loss}\")\n","print(f\"gradients: {grads}\")"]},{"cell_type":"markdown","metadata":{"id":"q9dQh9DdLYPE"},"source":["#### Training the model using Jax"]},{"cell_type":"markdown","metadata":{"id":"q1I8M0zkhAg3"},"source":["**Gradient descent:**\n","\n","Now we have all the basic pieces required to train a machine learning model. Recall the goal is to find the parameters that will make the loss as small as possible. This can be achieved by following the gradient in the direction that reduces the loss. One popular algorithm for this in machine learning is the use of <font color='red'>gradient descent algorithm</font>. The algorithm works as follows:\n","\n","1.   Initialise the parameters with random values.\n","2.   Loop for a number of iterations and during each iteration update the parameters using the following formula.\n","\n","$$ \\mathbf{\\theta} = \\mathbf{\\theta} - η\\frac{∂\\mathcal{L}}{∂\\theta},$$\n","$\\eta$ is called the learning rate. It is a hyperparameter of the gradient descent algorithm meaning we have to choose it beforehand.\n","\n","Intuitively, if the current parameters are the optimal parameters then the gradients, $\\frac{\\partial \\mathcal{L}}{\\partial \\theta}$ will be zero and the parameters will stop changing. Hence one stopping criterion which we can use during training is checking when the parameters stop changing also known as convergence. When a single data point is used at every iteration to compute the gradient the algorithm is called <font color='red'>stochastic gradient descent</font>. When the entire training data is used the algorithm is called <font color='red'>batch gradient descent</font>. Traditionally the best approach is to use small chunks of the data at each step. This approach is called the <font color='red'>mini-batch gradient descent</font>. Most often in practice, people use the term stochastic gradient descent but they actually mean mini-batch gradient descent.\n","\n","Thus during training, we will loop through the datasets for each iteration. When we loop through the entire dataset we called that an epoch. Hence another familiar hyperparameter is the epoch.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qoFbSQWGhAg7"},"outputs":[],"source":["# @title Code demonstration: Batch gradient descent implementation\n","def batch_gradient_descent(loss_fn, params, training_data, val_data, learning_rate=0.01, num_epochs=20, batch_size=10):\n","  \"\"\"Batch gradient descent basic jax implementation.\n","\n","  Args:\n","    loss_fn\n","      the loss function for our model.\n","    params:\n","      the initial parameters of the model.\n","    training_data\n","      a tuple with the features and targets for training.\n","    val_data\n","      a tuple with the features and targets for validation.\n","    learning_rate\n","      learning rate\n","    num_epochs\n","      number of epochs\n","    batch_size:\n","      size of every mini batch\n","  \"\"\"\n","\n","  X_train, y_train = training_data\n","  X_val, y_val = val_data\n","\n","  num_samples, num_features = X_train.shape\n","\n","  # Create empty list to store the training and validation loss.\n","  loss_train = [] # training loss\n","  loss_val  = [] # valisation loss\n","\n","  # Define a function that computes loss and gradients\n","  loss_and_grad = jax.value_and_grad(loss_fn)\n","\n","  n_iter = 0 # number iterations\n","  for epoch in range(num_epochs):\n","    # Shuffle the data before every epoch\n","    shuffled_indices = np.arange(num_samples)\n","    np.random.shuffle(shuffled_indices)\n","\n","    for start_idx in range(0, num_samples, batch_size):\n","      end_idx = start_idx + batch_size\n","      if end_idx > num_samples:\n","        end_idx = num_samples\n","\n","      batch_indices = shuffled_indices[start_idx:end_idx]\n","      X_batch = X_train[batch_indices]\n","      y_batch = y_train[batch_indices]\n","\n","      # Compute loss and gradients using value_and_grad\n","      loss, grads = loss_and_grad(params, X_batch, y_batch)\n","      loss_train.append(loss)\n","\n","      # Compute the validation loss\n","      loss_v = loss_fn(params, X_val, y_val)\n","      loss_val.append(loss_v)\n","\n","      # Update the parameters\n","      params = jax.tree_map(lambda p, g: p -learning_rate*g, params, grads)\n","\n","      # Update the iter count\n","      n_iter += 1\n","\n","\n","  # Plot training and validation loss\n","  iters = range(1, n_iter+1)\n","  plt.plot(iters, loss_train, label='Training Loss')\n","  plt.plot(iters, loss_val, label='Validation Loss')\n","  plt.xlabel('Iteration')\n","  plt.ylabel('Loss')\n","  plt.title('Training and Validation Loss')\n","  plt.legend()\n","\n","  # Display the plot\n","  plt.show()\n","\n","  return params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gbBCDwQhAg8"},"outputs":[],"source":["# @title Let's create some dummy data to test the code\n","def create_dummy_data_linear_regression():\n","  \"\"\"We will generate some random data using our linear function above to test the gradient decent implementation\"\"\"\n","\n","  num_samples = 200\n","  num_features = 1  # Modify this to have more features\n","\n","  # Generate random X values in the range [0, 10] for each feature\n","  key = jax.random.PRNGKey(0)\n","  X = jax.random.uniform(key, (num_samples, num_features), minval=0, maxval=10)\n","\n","  # Generate y values based on a linear relationship with some noise\n","  w = jnp.array([3.0]*num_features)  # True coefficients for each feature\n","  b = jnp.array([5.0])\n","\n","  params = dict(w=w, b=b)\n","  y = linear_model(params, X)\n","\n","  # Add some noise\n","  noise = jax.random.normal(key, shape=(num_samples,))*0.30\n","  y = y + noise\n","\n","  # Step 2: Split the data into training and validation sets\n","  train_fraction = 0.8\n","  num_train_samples = int(train_fraction * num_samples)\n","\n","  # Shuffle the indices to randomly split the data\n","  key, subkey = jax.random.split(key)\n","  shuffled_indices = jax.random.permutation(subkey, jnp.arange(num_samples))\n","\n","  # Split the indices into training and validation sets\n","  train_indices = shuffled_indices[:num_train_samples]\n","  val_indices = shuffled_indices[num_train_samples:]\n","\n","  # Get the corresponding data points for training and validation sets\n","  X_train, y_train = X[train_indices], y[train_indices]\n","  X_val, y_val = X[val_indices], y[val_indices]\n","\n","  train_data = (X_train, y_train)\n","  val_data = (X_val, y_val)\n","\n","  # create some random initial params\n","  w_init = jax.random.normal(key, shape=(num_features,))\n","  b_init = 0.0\n","  initial_params = dict(w=w_init, b=b_init)\n","\n","  return train_data, val_data, initial_params\n","\n","\n","def plot_linear_fit(params, X, y):\n","  \"\"\"Overlay the data and fitted model\"\"\"\n","\n","  y_pred = linear_model(params, X).squeeze()\n","  xval = X[:,0]\n","\n","  plt.figure(figsize=(8, 6))\n","  plt.scatter(xval, y, label='Data', color='blue')\n","  plt.plot(xval, y_pred, label='Fit', color='red')\n","  plt.xlabel('X')\n","  plt.ylabel('Y')\n","  plt.legend()\n","  plt.title('Scatter Points and Fitted Curve')\n","  plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyvVrWO0YdDe"},"outputs":[],"source":["train_data, val_data, initial_params = create_dummy_data_linear_regression()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upnIeZ2Zaued"},"outputs":[],"source":["params = batch_gradient_descent(loss_fn, initial_params, train_data, val_data, learning_rate=0.01, num_epochs=2, batch_size=10)\n","\n","# plot the results on validation data\n","Xval, yval = val_data\n","plot_linear_fit(params, Xval, yval)"]},{"cell_type":"markdown","metadata":{"id":"qzpzC6C25R2K"},"source":["Our model seems to be **underfitting** that data because the fitted line is going through very few of the points.\n","\n","**Exercise:** Discuss with your neighbour how we can improve our model.\n","\n","**Code task:** Modify the learning rate, batch_size and the number of epochs and observe their effects on the results.\n","\n","**Tips:**\n","- In practice, people usually choose learning rates in the range of 0.01 and 1e-5.\n","- Small batch sizes can introduce too much noise in the gradients and this may affect the speed of convergence.\n","- On the other hand, large batch sizes may take longer to converge because parameters are not updated very frequently.\n","- Not that using a very high number of epochs will make the training take long because we did not include any stopping criterion."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rB8DMH4Z7seC"},"outputs":[],"source":["# @title Your code here\n","learning_rate = 3e-4 #@param {type:\"slider\", min:1e-5, max:1e-2, step:1e-4}\n","batch_size = 20 #@param {type:\"slider\", min:1, max:5000, step:10}\n","num_epochs = 100 #@param {type:\"slider\", min:2, max:500, step:20}\n","\n","params = batch_gradient_descent(loss_fn, initial_params, train_data, val_data, learning_rate=learning_rate, num_epochs=num_epochs, batch_size=batch_size)\n","\n","# plot the results on validation data\n","Xval, yval = val_data\n","plot_linear_fit(params, Xval, yval)"]},{"cell_type":"markdown","metadata":{"id":"BKtMEnRkhAg9"},"source":["2.2 Non linear regression and neural networks"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"xNYVOlb-bUml"},"outputs":[],"source":["# @title Helper code to plot non-linear data\n","def plot_nonlinear_data():\n","\n","  x = np.linspace(-5, 5, 100)\n","  y = np.cos(x)*x + x**2 + np.exp(-x/7)*3 + 0.3*x*np.sin(x)**4\n","\n","  plt.scatter(x, y)\n","  plt.title(\"Example of non linear data\")\n","  plt.show\n","\n","plot_nonlinear_data()"]},{"cell_type":"markdown","metadata":{"id":"n2FIcY0XAzFw"},"source":["Linear regression is a simple and powerful data inference method; however, it has limitations in capturing non-linear relationships. To model such complexities, we require more powerful models. For example, no single line will perfectly fit the data in the above figure. Nonlinear models, such as polynomials, exponentials, and trigonometric functions, offer solutions to this problem.\n","\n","Before the explosion of deep learning techniques, fitting pre-defined functions to datasets was the go-to machine learning approach. Examples of classical algorithms using this approach include <font color='red'>support vector machines, and naive Bayes</font>, among others.\n","\n","In this section, we will introduce <font color='red'>neural networks</font> which are at the heart of deep learning techniques and recent successes of machine learning."]},{"cell_type":"markdown","metadata":{"id":"XStsgHB2MarI"},"source":["#### Model representation\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"K7NYiMuVIUPR"},"source":["<center>\n","<img src=\"https://www.spotfire.com/content/dam/spotfire/images/graphics/inforgraphics/neutral-network-diagram.svg\" width=\"80%\" />\n","</center>\n","\n","      Image of a neural network with 3 hidden layers. Credit: https://www.tibco.com/reference-center/what-is-a-neural-network\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WAcehBE0J-G0"},"source":["Neural networks are a powerful class of machine learning models inspired by how the human brain functions. Unlike linear regression, which applies a single transformation to the data, neural networks process input data through a series of transformations before reaching the final predictive layer. The term <font color='red'>Deep Learning</font> arises from the numerous transformations applied to the input data.\n","\n","In the image above, the circles represent nodes, and the links connecting them represent the model's parameters."]},{"cell_type":"markdown","metadata":{"id":"fkpytbBzMvMj"},"source":["#### Activation functions\n","\n","Activation functions are essential in neural networks. The input to every node is a linear function of all the nodes from the previous layer. Without applying an activation function, also called a non-linearity, the entire neural network, no matter how many layers it has, reduces to a simple linear model. Thus, activation functions are used to break the linearity and ensure that we build a complex non-linear function.\n","\n","The equation for node \\(i\\) in layer \\(j\\) of a neural network can be expressed as follows:\n","\n","$$ \\text{Output}_{ij} = \\text{Activation Function} \\left( \\sum_{k=1}^{n} \\text{Weight}_{ijk} \\times \\text{Output}_{(j-1)k} + \\text{Bias}_{ij} \\right)$$\n","\n","Where:\n","- $\\text{Output}_{ij}$ is the output of node $i$ in layer $j$.\n","- $\\text{Weight}_{ijk}$ is the weight connecting node $i$ in layer $j$ to node $k$ in layer $j-1$.\n","- $\\text{Output}_{(j-1)k}$ is the output of node $k$ in layer $j-1$.\n","- $\\text{Bias}_{ij}$ is the bias term for node $i$ in layer $j$.\n","- $\\text{Activation Function}$ is the chosen activation function that introduces nonlinearity to the output of the neuron.\n"]},{"cell_type":"markdown","metadata":{"id":"qnXa2-o8RFK3"},"source":["Some popular activation functions include:\n","\n","- $\\text{ReLU}(x) \\, = \\, \\text{max}(0, x)$\n","\n","    The Rectified Linear Unit (ReLU) is the most popular activation function. It maps it input to range $[0, ∞]$ mapping all negativie values to 0. Both the function and its derivitate are monotonic. However this activation function has the problem it turns all negative inputs to 0 and their descreases the ability of the model to fit data properly.\n","\n","- $\\text{Sigmoid}(x) \\, =\\, \\frac{1}{1+e^{-x}}$\n","\n","    The sigmoid activation maps input the range $[0, 1]$. This is ideal for predicting probabilities. The function is differentiable and monotonic but its derivative is not monotonic. Because its derivative is not monotonic it is not ideal to use this activation in hidden layers as it blocks information transfer between layers. Hence most often activation is applied only to output layers.\n","\n","- $\\text{tanh}(x)\\, = \\, \\frac{e^x - x^{-x}}{e^x + e^{-x}},$\n","  \n","     The $tanh$ activation is similar to the sigmoid activation but it maps inputs to range $[-1, 1]$. This wider range allows for a much better spread when predicting probabilities. Similarly to the sigmoid activation, the $tanh$ is most often applied to the output layers of neural networks.\n","\n","\n","\n","Let's implement the popular [ReLU](https://arxiv.org/https://arxiv.org/abs/1803.08375abs/1803.08375) activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17JUU2WIMOAO"},"outputs":[],"source":["# Implementation of relu using simple python.\n","\n","def relu(x):\n","  if x > 0 :\n","    return x\n","  else:\n","    return 0\n","\n","def plot_activation(act_fn, label=\"act_fn\"):\n","    max_int = 5\n","    # Generete 100 evenly spaced points from -max_int to max_int\n","    x = np.linspace(-max_int, max_int, 1000)\n","    y = np.array([act_fn(xi) for xi in x])\n","    plt.plot(x, y, label=label)\n","    plt.legend(loc=\"upper left\")\n","    plt.xticks(np.arange(min(x), max(x) + 1, 1))\n","    plt.show()\n","\n","plot_activation(relu, label='ReLU')"]},{"cell_type":"markdown","metadata":{"id":"NAQn8NUPhAg-"},"source":["**Code Task:** Implement and plot another activation function of your choice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bSCO__yzY5vj"},"outputs":[],"source":["# @title Your code here\n","def act_fn(x):\n","    # type your code here\n","\n","    y = ...#\n","    return y\n","\n","# Call the plotting function\n","plot_activation(act_fn, label=....) # update this\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3Wrxt2orM7sk"},"source":["#### Building a simple neural network model with Jax\n","\n","Fortunately, they are different high-level modules that can be used to develop deep neural networks and we don't have to implement everything from scratch. For example, for Jax based model we can use [haiku]( https://dm-haiku.readthedocs.io/en/latest/) and [flax](https://flax.readthedocs.io/en/latest/getting_started.html). Moreover, advanced optimisation techniques can be implemented using [optax](https://optax.readthedocs.io/en/latest/). In this section, we will use flax to implement a simple 4 layer neural network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36LsHOHxjPuH"},"outputs":[],"source":["# @title Code demonstration: building a simple neural network with flax\n","# Code for a 4-layer neural network using haiku.\n","# Here assume all the hidden layers have the same number of nodes.\n","# We will use the same activation relu for all the layers except the last layer.\n","\n","class Network(nn.Module):\n","  hidden_size: int\n","  output_size: int\n","\n","  @nn.compact\n","  def __call__(self, x):\n","    # First layer with ReLU activation\n","    x = nn.Dense(self.hidden_size)(x)\n","    x = jax.nn.relu(x)\n","\n","    # Second layer\n","    x = nn.Dense(self.hidden_size)(x)\n","    x = jax.nn.relu(x)\n","\n","    # Third (output) layer with no activation applied\n","    x = nn.Dense(self.output_size)(x)\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"lCOgpUEsnvCK"},"source":["The cell above is a basic example of how we can define a neural network using flax. Each linear transformation is implemented using the `nn.Dense` function, and we use `jax.nn.relu` to apply non-linearities to the output of each layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYMLCHd2nSS2"},"outputs":[],"source":["# @title Code demonstration: intialising the model\n","seed = 32\n","input_size = 4\n","hidden_size = 5\n","output_size = 1\n","\n","# Calling the build_neural_network function and applying the required transformations\n","model = Network(hidden_size, output_size)\n","\n","key = jax.random.PRNGKey(seed)\n","dummy = jnp.zeros((1, input_size), dtype=float)\n","initial_params = model.init(key, dummy)\n","\n","# Let's use the CLU: https://github.com/google/CommonLoopUtils to examine the shape of the parameters\n","print(parameter_overview.get_parameter_overview(initial_params, include_stats=False))"]},{"cell_type":"markdown","metadata":{"id":"UW39m5wCDrBL"},"source":["**Exercise:** Do you understand the shape of the different parameters?"]},{"cell_type":"markdown","metadata":{"id":"0Q1_OKVVvR69"},"source":["The above cell demonstrates how to create an instance of the model and get initial parameters. After creating an instance of the model using the `Network` class we call the `init` function with a `jax.random.PRNGKey` and some dummy inputs from which the shape of the parameters will be inferred.  "]},{"cell_type":"markdown","metadata":{"id":"KW6s0Pn3vwy7"},"source":["To apply the model to some data we need to call `model.apply` with the current parameters and the input data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3YtVINzqWP7"},"outputs":[],"source":["z = model.apply(initial_params, dummy)\n","print(f\"Model ouput shape: {z.shape}, Input shape: {dummy.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"fbTsk0MdhAhC"},"source":["## **Classification**\n","Now that we are familiar with the fundamentals of model fitting and we know how to build neural networks, we will now focus on our original objective and build our mnist digit classifier."]},{"cell_type":"markdown","metadata":{"id":"wMgxJU0TOX6O"},"source":["### 3.1 Logistic regression\n","\n","Linear regression aims to find a function $f$ that maps our **inputs $x$**, where $x \\in \\mathbb{R}^d$ to the corresponding **output/target - $y$**, where $y \\in \\mathbb{R}^n$ (output values are continous). Contrary to regression, the **output/target -$y$** can only take on certain values in logistic regression. When the **target** can only take on one of two values, the algorithm is called **Binary Classification**. When we have more than two categories, it is called a **Multi-class Classification**.\n","\n","Hence the aim of Logistic regression (in the Binary classification case) is to map **inputs $x$**, where $x \\in \\mathbb{R}^d$ to $y$, where $y \\in \\{0,1\\}$.\n","\n","For example, if we are building an image classifier for cats and dogs, 1 may be used to represent the target values for cats and 0 for dogs."]},{"cell_type":"markdown","metadata":{"id":"SE1L3rmaO4UP"},"source":["#### Logits and sigmoid activation function\n","The target values for logistic regression problems are discrete. It is not straightforward how to define a model function that outputs discrete values. Hence we design the model to output probabilities instead. Recall that probabilities only lie in the range of values $[0,1]$, thus we need a function that maps the output to probabilities. As mentioned earlier a good activation function we can use in this case is the **Sigmoid** activation function.\n","<br>\n","<center>\n"," $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n","\n"," ![sigmoid.png](data:image/png;base64,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)\n","</center>\n","<br>\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"yAWfZN-7oadX"},"source":["**Cross entropy loss function**\n","\n","In binary classification, we can only have one of two values for the targets. Using the mean square error as before generally doesn't perform well in logistic regression. The most common loss function that works best for logistic regression problems is the <font color='red'>cross entropy loss function</font> defined as follows:\n","<br>\n","<center>\n"," $$ -y_i \\log(p_i) - (1-y_i) \\log (1-p_i),$$\n","</center>\n","where $p_i = \\sigma (z)$ with $z$ being the output of our model function.\n","<br>\n","\n","**Code task**:\n","1. Implement the sigmoid activation function.\n","2. Implement the cross entropy loss function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9CiEUERAHJ4"},"outputs":[],"source":["def sigmoid(x):\n","    \"\"\"sigmoid function 1/1+e^-x\"\"\"\n","\n","    prob = ... # update me\n","\n","    return prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YzKHb9DEAaMI"},"outputs":[],"source":["# @title Run me to test your code\n","def test_sigmoid_fn():\n","  x  = np.array([0.7, 0.3, 0.8, 0.2])\n","  assert jnp.allclose(sigmoid(x), jax.nn.sigmoid(x)), \"Test failed!\"\n","  print(\"Nice! Your answer looks correct!\")\n","\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"t75OVB1oBZOZ"},"outputs":[],"source":["# @title sigmoid solution (Try not to peek until you've given it a good try!')\n","def sigmoid(x):\n","  prob = 1/(1+jnp.exp(-x))\n","\n","  return prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-YTxxNnuOKI"},"outputs":[],"source":["def cross_entropy_loss(predictions, targets):\n","    # you need to make sure we never have log of 0\n","\n","    # use sigmoid to compute the probs from the predicitions\n","    probs = ... # update me\n","\n","    # your code here\n","    loss = ... # update me\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUW87CN4u9sG"},"outputs":[],"source":["# @title Run me to test your code\n","def test_cross_entropy_loss():\n","  predictions = np.array([0.7, 0.3, 0.8, 0.2])\n","  targets = np.array([1, 0, 1, 0])\n","\n","  # Expected cross-entropy loss for the test data\n","  expected_loss = 0.60669523\n","\n","  # Calculate the cross-entropy loss using the implemented function\n","  computed_loss = cross_entropy_loss(predictions, targets)\n","\n","  assert jnp.isclose(computed_loss, expected_loss), \"Test failed!\"\n","\n","  # If the assert statement does not raise an exception, the test is passed.\n","  print(\"Nice! Your anwser looks correct\")\n","\n","  return\n","\n","test_cross_entropy_loss()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Y0VbBhG_u_UL"},"outputs":[],"source":["# @title Cross entropy loss solution (Try not to peek until you've given it a good try!')\n","def cross_entropy_loss(preds, targets):\n","    eps = 1e-15\n","    probs = sigmoid(preds)\n","\n","    loss = -targets*jnp.log(probs+eps) - (1-targets)*jnp.log(1-probs+eps)\n","\n","    return jnp.mean(loss)"]},{"cell_type":"markdown","metadata":{"id":"HjQNjDC2cG2t"},"source":["#### Extending to Multi-class classification"]},{"cell_type":"markdown","metadata":{"id":"Dlr8evx-dCoE"},"source":["In multi-class classification, the machine learning model is designed to handle more than two classes, where each class represents a different category or label. For example, in the case of a single-digit classifier, there are 10 classes, each corresponding to a digit from 0 to 9.\n","\n","The model's output is typically a probability distribution over all possible classes, with each class having an associated probability. The dimensions of the output vector match the number of classes, so for a classifier with 3 different classes, the output vector will have a dimension of 3.\n","\n","To make a prediction, the model selects the class with the highest probability as the predicted class for the input data point."]},{"cell_type":"markdown","metadata":{"id":"BqLug2dpf8Zn"},"source":["**One-hot encoding**\n","\n","One-hot encoding is a common technique used to represent categorical variables, such as class labels, as binary vectors. In the case of multi-class classification with 3 classes, the targets are transformed into one-hot encoded vectors as follows:\n","\n","Class 1: [1, 0, 0]: This means the data point belongs to class 1, and the first element in the vector is set to 1, while the other elements are set to 0.\n","\n","Class 2: [0, 1, 0]: This means the data point belongs to class 2, and the second element in the vector is set to 1, while the other elements are set to 0.\n","\n","Class 3: [0, 0, 1]: This means the data point belongs to class 3, and the third element in the vector is set to 1, while the other elements are set to 0.\n","\n","We can use `jax.nn.one_hot` function to one-hot encode our data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_-jrxWPjVzf"},"outputs":[],"source":["# An example using one hot encoding\n","num_classes =  3\n","targets = jnp.array([2, 0, 1])\n","one_hot_targets = jax.nn.one_hot(targets, num_classes)\n","print(f\"Example of One hot encordings: {one_hot_targets}\")"]},{"cell_type":"markdown","metadata":{"id":"ckIDzLRgj7_b"},"source":["**Exercise**: Discuss with your neighbour how we should define the loss function in the case of multi-class classification."]},{"cell_type":"markdown","metadata":{"id":"HMrwPge_lzVt"},"source":["**Solution**: The loss function for a multi-classification is computed similarly to that of a binary classifier. However in this case we define the loss as the sum of the loss for each of the individual classes.\n","<br>\n","<center>\n"," $$ \\sum_c -y^c_i \\log(p^c_i),$$\n","</center>\n","where $p^c_i = \\text{softmax}(z) = \\frac{e^{z^c_i}}{\\sum_c e^{z^c_i}}$ with $z$ being the output of our model function.\n","<br>\n","The main difference here is that we use a $\\text{softmax}$ activation function instead of $\\text{sigmoid}$ as for the binary case.\n","\n","**Exercise 3 [OPTIONAL]**: Do your get the initution why this formula is similar to that for the binary case?\n","\n","**Solution**: Scroll to the [Appendix](#scrollTo=fRYbQvz01Zlm)."]},{"cell_type":"markdown","metadata":{"id":"2QnINsMrpTYP"},"source":["**Code task**:\n","  1. Implement the softmax activation function\n","  2. Implement a cross entropy loss function for multiclass classification using softmax and one hot encoding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DWDGiKZpRX0"},"outputs":[],"source":["def softmax(logits):\n","  \"\"\"Compute softmax: `exp(x)/sum(exp(x))`\n","\n","  Args:\n","    logits: array of shape (num_samples, num_classes)\n","\n","  Return:\n","    probs: array of shape (num_samples, num_classes)\n","  \"\"\"\n","\n","  # your code here\n","  # make sure you sum across the right axis\n","\n","  probs = ... # update me\n","\n","  return probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlBBgQafDsHQ"},"outputs":[],"source":["# @title Run me to test your code\n","def test_softmax():\n","  x = jnp.array([[1.0, 0.4, 0.3], [10.0, 4.6, 8.9]])\n","  assert jnp.allclose(softmax(x), jax.nn.softmax(x, axis=-1))\n","  print(\"Nice! Your answer looks correct.\")\n","\n","test_softmax()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"5KKM6hKnxFSK"},"outputs":[],"source":["# @title softmax solution (Try not to peek until you've given it a good try!')\n","def softmax(logits):\n","  exp_logits = jnp.exp(logits)\n","  return exp_logits / jnp.sum(exp_logits, axis=-1, keepdims=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIVjt6T4xTQX"},"outputs":[],"source":["def cross_entropy_softmax_loss(predictions, targets):\n","    \"\"\"Compute the cross entropy softmax loss function\n","\n","      Args:\n","        predictions: (num_samples, num_classes)\n","        targets: (num_samples)\n","    \"\"\"\n","\n","    # Compute the softmax probabilities\n","    probs = ... # update me\n","\n","    num_classes = ... # update me\n","\n","    # One-hot encode the targets\n","    targets_one_hot = ... # update me\n","\n","    # Compute the cross-entropy loss\n","    eps = 1e-15\n","    probs += eps # to avoid calling log with 0 values\n","\n","    loss = ... # update me\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"8Tsbe8OazNq5"},"outputs":[],"source":["# @title Run me to test your code\n","def test_cross_entropy_softmax_loss():\n","  # Fixed predictions (logits) for each class\n","  predictions = jnp.array([[1.5, 0.3, 2.7],\n","        [0.8, 1.2, 3.1], [2.3, 1.7, 0.5],\n","        [3.0, 0.5, 1.2], [0.2, 2.8, 1.0]])\n","\n","  # Fixed true class labels\n","  targets = jnp.array([2, 1, 0, 0, 2])\n","\n","  # Expected loss computed manually\n","  expected_loss = 1.0456787\n","\n","  # Compute the cross-entropy softmax loss using your implementation\n","  loss = cross_entropy_softmax_loss(predictions, targets)\n","\n","  # Check if the computed loss matches the JAX built-in loss\n","  assert jnp.allclose(loss, expected_loss), \"Loss value do not match!\"\n","\n","  print(\"Nice! Your answer looks correct.\")\n","\n","test_cross_entropy_softmax_loss()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"WG5z8vOjfYiU"},"outputs":[],"source":["# @title Cross entropy softmax solution (Try not to peek until you've given it a good try!')\n","def cross_entropy_softmax_loss(predictions, targets):\n","    \"\"\"Compute the cross entropy softmax loss function\n","\n","      Args:\n","        predictions: (num_samples, num_classes)\n","        targets: (num_samples)\n","    \"\"\"\n","\n","    # Compute the softmax probabilities\n","    probs = softmax(predictions) # update me\n","\n","    num_classes = predictions.shape[-1]\n","\n","    # One-hot encode the targets\n","    targets_one_hot = jax.nn.one_hot(targets, num_classes) # update me\n","\n","    # Compute the cross-entropy loss\n","    eps = 1e-15\n","    probs += eps # to avoid calling log with 0 values\n","\n","    loss_i = jnp.sum(-targets_one_hot*jnp.log(probs), axis=-1) # update me\n","\n","    return jnp.mean(loss_i)"]},{"cell_type":"markdown","metadata":{"id":"EcXXE56hPOhK"},"source":["#### Building a simple neural network for classification\n","\n","In this section, we will assemble all the pieces and train a deep neural network for classification. Let's recall all the tools we mentioned initially that are necessary to train a machine learning model.\n","\n","1. Dataset: we need to have a dataset which we will split into training and validation sets in the ratio 80:20.\n","2. A model function.\n","3. A loss function.\n","4. An optimisation algorithm.\n","\n","We will load the data using [sklearn](https://scikit-learn.org/stable/datasets/toy_dataset.html). We have not discussed data preprocessing but in practice, we usually have to preprocess our datasets before using them for training. Such steps may include for example visualising the data to have intuition, identifying outliers, transforming and even dropping some features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"II8gN_lTKoQI"},"outputs":[],"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import jax\n","import jax.numpy as jnp\n","from typing import NamedTuple, Any\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Let re-adapt our batch gradient descent function\n","def batch_gradient_descent(loss_fn, params, training_data, val_data, learning_rate=0.01, num_epochs=20, batch_size=10):\n","  \"\"\"Batch gradient descent basic jax implementation.\n","\n","  Args:\n","    loss_fn\n","      the loss function for our model.\n","    params:\n","      the initial parameters of the model.\n","    training_data\n","      a tuple with the features and targets for training.\n","    val_data\n","      a tuple with the features and targets for validation.\n","    learning_rate\n","      learning rate\n","    num_epochs\n","      number of epochs\n","    batch_size:\n","      size of every mini batch\n","  \"\"\"\n","\n","  X_train, y_train = training_data\n","  X_val, y_val = val_data\n","\n","  num_samples, num_features = X_train.shape\n","\n","  # Create empty list to store the training and validation loss.\n","  loss_train = [] # training loss\n","  loss_val  = [] # valisation loss\n","\n","  # Define a function that computes loss and gradients\n","  loss_and_grad = jax.value_and_grad(loss_fn)\n","\n","  for epoch in range(num_epochs):\n","    # Shuffle the data before every epoch\n","    shuffled_indices = np.arange(num_samples)\n","    np.random.shuffle(shuffled_indices)\n","\n","    loss_train_epoch = []\n","\n","    for start_idx in range(0, num_samples, batch_size):\n","      end_idx = start_idx + batch_size\n","      if end_idx > num_samples:\n","        end_idx = num_samples\n","\n","      batch_indices = shuffled_indices[start_idx:end_idx]\n","      X_batch = X_train[batch_indices]\n","      y_batch = y_train[batch_indices]\n","      # Compute loss and gradients using value_and_grad\n","      loss, grads = loss_and_grad(params, X_batch, y_batch)\n","      loss_train_epoch.append(loss)\n","\n","      # Update the parameters\n","      params = jax.tree_map(lambda p, g: p -learning_rate*g, params, grads)\n","\n","    # We need to turn the list in to an array before applying jnp.mean\n","    mean_loss = jnp.mean(jnp.array(loss_train_epoch))\n","    loss_train.append(mean_loss)\n","\n","    # Compute the validation loss at the end of the epoch\n","    loss_v = loss_fn(params, X_val, y_val)\n","    loss_val.append(loss_v)\n","\n","  # Plot training and validation loss\n","  epochs = range(1, num_epochs+1)\n","  plt.plot(epochs, loss_train, label='Training Loss')\n","  plt.plot(epochs, loss_val, label='Validation Loss')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Loss')\n","  plt.title('Training and Validation Loss')\n","  plt.legend()\n","\n","  # Display the plot\n","  plt.show()\n","\n","  return params\n","\n","# Load the mnist dataset\n","def load_dataset(seed):\n","  mnist = fetch_openml(name='mnist_784', version=1, as_frame=False, parser='auto')\n","  # Extract the data and labels\n","  images, labels = mnist.data, mnist.target\n","\n","  # These images consist of integer values from 0 to 255.0\n","  # We scale the images to min and max of 1\n","  x_max = 255.0\n","  x_min = 0.0\n","\n","  images = (images - x_min)/(x_max - x_min)\n","  images = images.astype(jnp.float32)\n","  labels = labels.astype(jnp.float32)\n","\n","  # These are images of shape 28x28 which have been flatten to shape 784\n","  X_train, X_test, y_train, y_test = train_test_split(\n","      images, labels, test_size=0.2, train_size=0.8, random_state=seed\n","  )\n","\n","  train_dataset = (X_train, y_train)\n","  test_dataset = (X_test, y_test)\n","\n","  return train_dataset, test_dataset\n","\n","training_data, val_data = load_dataset(32)"]},{"cell_type":"markdown","metadata":{"id":"fcJMGW7HWkWI"},"source":["**Code task:**\n","1. Build a neural network that outputs logits for each of the 10 classes.\n","2. Initialise your model with some dummy input.\n","3. Define your softmax cross entropy function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBOzpb2YXzvR"},"outputs":[],"source":["# @title Your code here\n","class Network(nn.Module):\n","  hidden_size: int\n","  output_size: int\n","\n","  @nn.compact\n","  def __call__(self, x):\n","    # First layer with ReLU activation\n","    x = nn.Dense(self.hidden_size)(x)\n","    x = jax.nn.relu(x)\n","\n","    # Second layer\n","    x = ...  # update me\n","    x = ...  # update me\n","\n","    # Third (output) layer with no activation applied\n","    x = nn.Dense(self.output_size)(x)\n","\n","    return x\n","\n","# transform and intialiase the model.\n","seed = 32\n","input_size = 784 # remember our features are images of shape 28x28 flatten\n","hidden_size = ... # update me\n","output_size = ... # update me (hint: number classes)\n","\n","# instantiate the model\n","model = Network... # update me\n","\n","key = jax.random.PRNGKey(seed)\n","dummy = jnp.zeros((1, input_size), dtype=float)\n","initial_params = model.init(key, dummy)\n","\n","def softmax(logits):\n","  exp_logits = jnp.exp(logits)\n","  return exp_logits / jnp.sum(exp_logits, axis=-1, keepdims=True)\n","\n","\n","def cross_entropy_softmax_loss(params, X, targets):\n","    \"\"\"Compute the cross entropy softmax loss function\n","\n","      Args:\n","        params: model parameters\n","        X: features arrary (num_samples, num_features)\n","        targets: (num_samples)\n","    \"\"\"\n","\n","    # use the model to compute the predictions\n","    preds = model.apply(params, X)\n","\n","    # Compute the softmax probabilities\n","    probs = softmax(preds)\n","\n","    num_classes = preds.shape[-1]\n","\n","    # One-hot encode the targets\n","    targets_one_hot = jax.nn.one_hot(targets, num_classes)\n","\n","    # Compute the cross-entropy loss\n","    eps = 1e-15\n","    probs += eps # to avoid calling log with 0 values\n","\n","    loss_i = jnp.sum(-targets_one_hot*jnp.log(probs), axis=-1)\n","\n","    return jnp.mean(loss_i)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"mBM7kwGjY4dr"},"outputs":[],"source":["# @title Sample solution (Try not to peek until you've given it a good try!')\n","class Network(nn.Module):\n","  hidden_size: int\n","  output_size: int\n","\n","  @nn.compact\n","  def __call__(self, x):\n","    # First layer with ReLU activation\n","    x = nn.Dense(self.hidden_size)(x)\n","    x = jax.nn.relu(x)\n","\n","    # Second layer\n","    x = nn.Dense(self.hidden_size)(x)\n","    x = jax.nn.relu(x)\n","\n","    # Third (output) layer with no activation applied\n","    x = nn.Dense(self.output_size)(x)\n","\n","    return x\n","\n","# transform and intialiase the model.\n","seed = 67\n","input_size = 784\n","hidden_size = 100\n","output_size = 10\n","\n","# Instantiate the model\n","model = Network(hidden_size, output_size)\n","\n","key = jax.random.PRNGKey(seed)\n","dummy = jnp.zeros((1, input_size), dtype=float)\n","initial_params = model.init(key, dummy)\n","\n","def softmax(logits):\n","  exp_logits = jnp.exp(logits)\n","  return exp_logits / jnp.sum(exp_logits, axis=-1, keepdims=True)\n","\n","def cross_entropy_softmax_loss(params, X, targets):\n","    \"\"\"Compute the cross entropy softmax loss function\n","\n","      Args:\n","        params: model params\n","        X: (num_features, num_classes)\n","        targets: (num_samples)\n","    \"\"\"\n","\n","    preds = model.apply(params, X)\n","\n","    # Compute the softmax probabilities\n","    probs = softmax(preds)\n","\n","    num_classes = preds.shape[-1]\n","\n","    # One-hot encode the targets\n","    targets_one_hot = jax.nn.one_hot(targets, num_classes)\n","\n","    # Compute the cross-entropy loss\n","    eps = 1e-15\n","    probs += eps # to avoid calling log with 0 values\n","\n","    loss_i = jnp.sum(-targets_one_hot*jnp.log(probs), axis=-1)\n","\n","    return jnp.mean(loss_i)\n"]},{"cell_type":"markdown","metadata":{"id":"GcSvlekHPWxW"},"source":["#### Training the model\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xed1mfr1cOzW"},"source":["**Code task:**\n","  1. Call the `batch_gradient_descent` function to train the model.\n","  2. Vary the `learning_rate` and the `batch_size` and observe the behaviour of the loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lslWzLP0cciM"},"outputs":[],"source":["params = batch_gradient_descent ... # update me"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZGTHUrTdW2x"},"outputs":[],"source":["# @title Sample solution (Try not to peek until you've given it a good try!')\n","params = batch_gradient_descent(cross_entropy_softmax_loss, initial_params, training_data, val_data, learning_rate=0.01, num_epochs=10, batch_size=1000)"]},{"cell_type":"markdown","metadata":{"id":"sGPvmGWkP1fT"},"source":["#### Evaluating the model\n","So far the only metric we have used to evaluate the performance of our model has been the loss function. However, when training a machine learning model, several other metrics can be used to assess the performance of the model. Furthermore, hyper-parameters are generally selected (fine-tuned) based on the most important metric we want to optimise. Below are some metrics that can be used for classification tasks.\n","*   **Accuracy**: This is the most common metric generally used in classification. It is a measure of the proportion of instances classified correctly. $$ \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}$$\n","\n","* **Precision**: This is a measure of the number of positive predictions. For example, if our model predicts 100 data points to belong to class 1, the precision is the percentage of these 100 data points that effectively belong to class 1. High precision is maybe necessary for example in medical diagnosis, where we don't want to make a wrong diagnosis on patients that leads to unnecessary treatment.\n","\n","* **Recall**: This is a measure of the model's ability to efficiently identify all positive instances. For example, if the dataset has 100 data points belonging to class 1, how many are effectively classified to belong to class 1? The recall is crucial in cases where we don't want to miss any positive instance. For example, if we have a security company, we don't want to wrongly classify the signal from a user as being safe while he is actually in danger."]},{"cell_type":"markdown","metadata":{"id":"-0htEsSspFQN"},"source":["**Let's use accuracy to evaluate the performance of our trained classifier.**\n","\n","Firstly let's define a prediction function that transforms the model output to class. Recall the output of the classifier is logits which correspond to unnormalised probabilities belonging to each class. Thus the predicted class is the one with the highest probability    \n","\n","**Code Task**\n","  1. Implement a function `model_predict` that selects the appropriate class from the output of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWMMpYSDhAhE"},"outputs":[],"source":["# @title Your code here\n","def model_predict(params, X):\n","    \"\"\"Use the model for predicition\n","\n","      args:\n","        params: model parameters\n","        X: features array (num_samples, num_features)\n","\n","      return\n","        pred: predicted class (num_samples, 1)\n","    \"\"\"\n","\n","    # call the model to compute the logits\n","    logits = model... # update me\n","    preds = ... # update me: hint use jnp.argmax\n","\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"3u3PzTGmxENi"},"outputs":[],"source":["# @title Run to test your code\n","def test_model_predict():\n","    features = val_data[0][0:10]\n","    preds = model_predict(params, features)\n","    expected = jnp.argmax(model.apply(params, features), axis=-1)\n","    assert jnp.array_equal(preds, expected), \"Failed! try again\"\n","    print(\"Nice! Your answer looks correct.\")\n","\n","test_model_predict()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"xhJbRdW8DsHS"},"outputs":[],"source":["# @title Solution model predict (Try not to peek until you've given it a good try!')\n","def model_predict(params, X):\n","    \"\"\"Use the model for predicition\n","\n","      args:\n","        params: model parameters\n","        X: features array (num_samples, num_features)\n","\n","      return\n","        pred: predicted class (num_samples, 1)\n","    \"\"\"\n","\n","    # call the model to compute the logits\n","    logits = model.apply(params, X)\n","    preds = jnp.argmax(logits, axis=-1)\n","\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"k-rRiOD2z5ks"},"outputs":[],"source":["# @title Compute the accuray of your model\n","def compute_accuracy(data):\n","  \"\"\"Compute the accuracy of the model\"\"\"\n","\n","  X, y_true = data\n","  y_pred = model_predict(params, X).squeeze()\n","\n","  acc = sum(y_pred==y_true)/len(y_true)\n","\n","  return acc\n","\n","train_acc = compute_accuracy(training_data)\n","val_acc = compute_accuracy(val_data)\n","print(f\"The training accuracy is {train_acc} while the validation accuracy is {val_acc}\")"]},{"cell_type":"markdown","metadata":{"id":"r5-yxk9e19q4"},"source":["Congratulations, we've just trained a machine learning model for classification using the popular mnist digit dataset.\n","\n","**Take home challenge**:\n","- Are you satisfied with the accuracy of your model?\n","- What can you do to improve the accuracy of the model?"]},{"cell_type":"markdown","metadata":{"id":"fV3YG7QOZD-B"},"source":["## Conclusion\n","**Summary:**\n","\n","- Machine learning is the science of using data to build intelligent systems.\n","- Deep learning is the subset of machine learning methods that uses neural networks.\n","- Optimisation is the process of finding the parameters that make the loss of a function as small as possible.\n","- JAX is a new popular framework that can be used to compute derivatives and train machine learning models.  \n","\n","**Next Steps:**\n","\n","- Follow all the links provided in this practical.\n","- Join the reinforcement learning practicals to taste a different flavour of machine learning.\n","\n","\n","**References:**\n","\n","1. https://d2l.ai/chapter_linear-networks/linear-regression.html\n","2. https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/ai-vs-machine-learning-vs-deep-learning\n","3. https://www.javatpoint.com/machine-learning\n","\n","\n","For other practicals from the Deep Learning Indaba, please visit [here](https://github.com/deep-learning-indaba/indaba-pracs-2023)."]},{"cell_type":"markdown","metadata":{"id":"742JhcnAxTof"},"source":["### Appendix\n","\n","### Basis of JAX [OPTIONAL]\n","Jax is very similar to numpy but they are some important minor differences we need to be aware of."]},{"cell_type":"markdown","metadata":{"id":"T221aJAVyjvj"},"source":["Similarities between JAX and Numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Co610zXhygak"},"outputs":[],"source":["# Create NumPy arrays\n","np_array1 = np.array([1, 2, 3])\n","np_array2 = np.array([4, 5, 6])\n","\n","# Create JAX arrays\n","jax_array1 = jnp.array([1, 2, 3])\n","jax_array2 = jnp.array([4, 5, 6])\n","\n","# Element-wise addition using NumPy\n","np_result = np_array1 + np_array2\n","print(\"NumPy result:\", np_result)\n","\n","# Element-wise addition using JAX\n","jax_result = jax_array1 + jax_array2\n","print(\"JAX result:\", jax_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5i-RM66zYz7"},"outputs":[],"source":["# Array concatenation using NumPy\n","np_array1 = np.array([1, 2, 3])\n","np_array2 = np.array([4, 5, 6])\n","np_concatenated = np.concatenate([np_array1, np_array2])\n","\n","# Array concatenation using JAX\n","jax_array1 = jnp.array([1, 2, 3])\n","jax_array2 = jnp.array([4, 5, 6])\n","jax_concatenated = jnp.concatenate([jax_array1, jax_array2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fz73kSvDzojV"},"outputs":[],"source":["# Element-wise functions using NumPy\n","np_array = np.array([0, np.pi/2, np.pi])\n","np_sin = np.sin(np_array)\n","\n","# Element-wise functions using JAX\n","jax_array = jnp.array([0, jnp.pi/2, jnp.pi])\n","jax_sin = jnp.sin(jax_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVj6HoN4z5KZ"},"outputs":[],"source":["# Reduction operations using NumPy\n","np_array = np.array([1, 2, 3])\n","np_sum = np.sum(np_array)\n","np_mean = np.mean(np_array)\n","\n","# Reduction operations using JAX\n","jax_array = jnp.array([1, 2, 3])\n","jax_sum = jnp.sum(jax_array)\n","jax_mean = jnp.mean(jax_array)"]},{"cell_type":"markdown","metadata":{"id":"etSsvtmQz9L9"},"source":["JAX and NumPy - Differences ❌\n","\n","Although JAX and NumPy have some similarities, they do have some important differences:\n","- Jax arrays are **immutable** (they can't be modified after they are created).\n","- The way they handle **randomness** -- JAX handles randomness explicitly.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mgu5mHNZ1Esn"},"source":["JAX arrays are immutable, while NumPy arrays are not.\n","\n","JAX and NumPy arrays are often interchangeable, **but** Jax arrays are **immutable** (they can't be modified after they are created). Allowing mutations makes transforms difficult and violates conditions for [pure functions](https://en.wikipedia.org/wiki/Pure_function)."]},{"cell_type":"markdown","metadata":{"id":"rf2bVtWr1QYX"},"source":["Let's see this in practice by changing the number at the beginning of an array."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aonuiSN81Ok5"},"outputs":[],"source":["# NumPy: mutable arrays\n","x = np.arange(10)\n","x[0] = 10\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"_bikd7W91eQf"},"source":["Let's try this in JAX."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kt9yRXan1mMO"},"outputs":[],"source":["# JAX: immutable arrays\n","# Should raise an error.\n","try:\n","    x = jnp.arange(10)\n","    x[0] = 10\n","except Exception as e:\n","    print(\"Exception {}\".format(e))"]},{"cell_type":"markdown","metadata":{"id":"YHRr6uKH1sQ0"},"source":["So it fails! We can't mutate a JAX array once it has been created. To update JAX arrays, we need to use [helper functions](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html) that return an updated copy of the JAX array.\n","\n","Instead of doing this `x[idx] = y`, we need to do this `x = x.at[idx].set(y)`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLL6d2p81xue"},"outputs":[],"source":["x = jnp.arange(10)\n","new_x = x.at[0].set(10)\n","print(f\" new_x: {new_x} original x: {x}\")"]},{"cell_type":"markdown","metadata":{"id":"w6ibwTBj14gw"},"source":["Note here that `new_x` is a copy and that the original `x` is unchanged."]},{"cell_type":"markdown","metadata":{"id":"Ik_8oN9m1_zS"},"source":["Randomness in NumPy vs JAX\n","\n","JAX is more explicit in Pseudo Random Number Generation (PRNG) than NumPy and other libraries (such as TensorFlow or PyTorch). [PRNG](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) is the process of algorithmically generating a sequence of numbers, which *approximate* the properties of a sequence of random numbers.  \n","\n","Let's see the differences in how JAX and NumPy generate random numbers."]},{"cell_type":"markdown","metadata":{"id":"jaWE-uiW2G4p"},"source":["In Numpy, PRNG is based on a global `state`\n","\n","Let's set the initial seed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wa5e2_gb2Jl9"},"outputs":[],"source":["# Set random seed\n","np.random.seed(42)\n","prng_state = np.random.get_state()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"-9X10jhocGaS"},"outputs":[],"source":["# @title Helper function to compare prng keys (Run Cell)\n","def is_prng_state_the_same(prng_1, prng_2):\n","    \"\"\"Helper function to compare two prng keys.\"\"\"\n","    # concat all elements in prng tuple\n","    list_prng_data_equal = [(a == b) for a, b in zip(prng_1, prng_2)]\n","    # stack all elements together\n","    list_prng_data_equal = np.hstack(list_prng_data_equal)\n","    # check if all elements are the same\n","    is_prng_equal = all(list_prng_data_equal)\n","    return is_prng_equal"]},{"cell_type":"markdown","metadata":{"id":"yCHvH8DZ3Aro"},"source":["Let's take a few samples from a Gaussian (normal) Distribution and check if PRNG keys/global state change."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSixAoOQ2QU9"},"outputs":[],"source":["print(\n","    f\"sample 1 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",")\n","prng_state = np.random.get_state()\n","print(\n","    f\"sample 2 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",")\n","prng_state = np.random.get_state()\n","print(\n","    f\"sample 3 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"dlwT1pZH4M7C"},"source":["Numpy's global random state is updated every time a random number is generated, so *sample 1 != sample 2 != sample 3*.\n","\n","Having the state automatically updated, makes it difficult to handle randomness in a **reproducible** way across different threads, processes and devices."]},{"cell_type":"markdown","metadata":{"id":"eNQW9JwK4Yp6"},"source":["In JAX, PRNG is explicit.\n","\n","In JAX, for each random number generation, you need to explicitly pass in a random key/state.\n","\n","Passing the same state/key results in the same number being generated. This is generally undesirable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qd0PAWvf4KtX"},"outputs":[],"source":["from jax import random\n","\n","key = random.PRNGKey(42)\n","print(f\"sample 1 = {random.normal(key)}\")\n","print(f\"sample 2 = {random.normal(key)}\")\n","print(f\"sample 3 = {random.normal(key)}\")"]},{"cell_type":"markdown","metadata":{"id":"iUpdRj074oYO"},"source":["To generate different and independent samples, you need to manually split the keys."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82xoxsrF4vls"},"outputs":[],"source":["from jax import random\n","\n","key = random.PRNGKey(42)\n","print(f\"sample 1 = {random.normal(key)}\")\n","\n","# We split the key -> new key and subkey\n","new_key, subkey = random.split(key)\n","\n","# We use the subkey immediately and keep the new key for future splits.\n","# It doesn't really matter which key we keep and which one we use immediately.\n","print(f\"sample 2 = {random.normal(subkey)}\")\n","\n","# We split the new key -> new key2 and subkey\n","new_key2, subkey = random.split(new_key)\n","print(f\"sample 3 = {random.normal(subkey)}\")"]},{"cell_type":"markdown","metadata":{"id":"C2wiRBEo5OQb"},"source":["By using JAX, we can more easily reproduce random number generation in parallel across threads, processes, or even devices by explicitly passing and keeping track of the prng key (without relying on a global state that automatically gets updated)."]},{"cell_type":"markdown","metadata":{"id":"kh_8f4gKyufu"},"source":["### Derivation of partial derivatives for exercise 2 [OPTIONAL]\n","Derive $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}}$:\n","\\begin{aligned}\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{ \\partial}{\\partial \\mathbf{w}} (\\frac{1}{m} \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2) \\quad \\text{: Definition of $\\mathcal{L}$} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{1}{m} \\frac{ \\partial }{\\partial \\mathbf{w}} ( \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2) \\quad \\text{: Constant multiple rule} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{1}{m} \\sum_{i=1}^m \\frac{ \\partial }{\\partial \\mathbf{w}} (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2 \\quad \\text{: Sum Rule - derivative of sum is sum of derivatives.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{1}{m} \\sum_{i=1}^m 2 (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) \\frac{ \\partial }{\\partial \\mathbf{w}}(y_i -(\\mathbf{w}^T \\mathbf{x}_i + b))  \\quad \\text{: Power Rule + Chain Rule.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{1}{m} \\sum_{i=1}^m 2 (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) (-\\mathbf{x}_i)  \\quad \\text{: Compute derative.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{2}{m} \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) (-\\mathbf{x}_i)  \\quad \\text{: Factor constant out of summation.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = \\frac{2}{m} \\sum_{i=1}^m \\mathbf{x}_i((\\mathbf{w}^T \\mathbf{x}_i + b) -y_i ) \\quad \\text{: Rearrange.} \\\\  \n","\\end{aligned}\n","\n","Derive $\\frac{\\partial \\mathcal{L}}{\\partial b}$:\n","\\begin{aligned}\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{ \\partial}{\\partial b} (\\frac{1}{m} \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2) \\quad \\text{: Definition of $\\mathcal{L}$} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{1}{m} \\frac{ \\partial }{\\partial b} ( \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2) \\quad \\text{: Constant multiple rule} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{1}{m} \\sum_{i=1}^m \\frac{ \\partial }{\\partial b} (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b))^2 \\quad \\text{: Sum Rule - derivative of sum is sum of derivatives.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{1}{m} \\sum_{i=1}^m 2 (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) \\frac{ \\partial }{\\partial b}(y_i -(\\mathbf{w}^T \\mathbf{x}_i + b))  \\quad \\text{: Power Rule + Chain Rule.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{1}{m} \\sum_{i=1}^m 2 (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) (-1)  \\quad \\text{: Compute derative.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{2}{m} \\sum_{i=1}^m (y_i - (\\mathbf{w}^T \\mathbf{x}_i + b)) (-1)  \\quad \\text{: Factor constant out of summation.} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial b} & = \\frac{2}{m} \\sum_{i=1}^m ((\\mathbf{w}^T \\mathbf{x}_i + b) -y_i ) \\quad \\text{: Rearrange.} \\\\  \n","\\end{aligned}"]},{"cell_type":"markdown","metadata":{"id":"fRYbQvz01Zlm"},"source":["### Intuition for multi-class CE loss: exercise 3 [OPTIONAL]\n","\n","For binary classifies we use the following formula for the cross entropy loss\n"," $$ -y_i \\log(p_i) - (1-y_i) \\log (1-p_i).$$\n","\n","Recall in binary classier we have one class, so the output of our model is the probability, $p$ of belonging to that class. Instead, we can treat our binary classifier as two classes defined as follows\n","  - Class 1: Belonging to the class in question.\n","  - Class 2: Not belonging to the class.\n","\n","Then if the probability for the data point $y$_i of belonging to Class 1 is $p$_i, this means its probability of not belonging to Class 1 which is equivalent to belonging to Class 2 is $(1-p_i)$. Anagoulsy since target values are one hot encoded for a multi-class classification if $y_i$ is the label that it indicates if the data point belongs to Class 1 or not the corresponding label for belonging to Class 2 will be $(1 - y_i)$. Hence we can rewrite our cross entropy loss in compact form as follows\n","$$ \\sum_c -y^c_i \\log(p^c_i).$$"]},{"cell_type":"markdown","metadata":{"id":"4w0pspzitrii"},"source":[]},{"cell_type":"markdown","metadata":{"id":"s75zkKGJ9QRn"},"source":["**References:**\n","\n","1. https://d2l.ai/chapter_linear-networks/linear-regression.html\n","2. https://jax.readthedocs.io/en/latest/notebooks/quickstart.html\n","3. https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/ai-vs-machine-learning-vs-deep-learning\n","\n","\n","For other practicals from the Deep Learning Indaba, please visit [here](https://github.com/deep-learning-indaba/indaba-pracs-2023)."]},{"cell_type":"markdown","metadata":{"id":"o1ndpYE50BpG"},"source":["## Feedback\n","\n","Please provide feedback that we can use to improve our practicals in the future."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMk4EcMcUUPd"},"outputs":[],"source":["# @title Generate Feedback Form. (Run Cell)\n","from IPython.display import HTML\n","\n","HTML(\n","    \"\"\"\n","<iframe\n","\tsrc=\"https://forms.gle/Cg9aoa7czoZCYqxF7\",\n","  width=\"80%\"\n","\theight=\"1200px\" >\n","\tLoading...\n","</iframe>\n","\"\"\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"oglV4kHMWnIN"},"source":["<img src=\"https://baobab.deeplearningindaba.com/static/media/indaba-logo-dark.d5a6196d.png\" width=\"50%\" />"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Intro_ML_English_Prac.ipynb","timestamp":1707854534002}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.5"},"vscode":{"interpreter":{"hash":"145833166d986a8417df3c7acb65d917d84b716b5a452e57fcacdc66f1a168c9"}}},"nbformat":4,"nbformat_minor":0}