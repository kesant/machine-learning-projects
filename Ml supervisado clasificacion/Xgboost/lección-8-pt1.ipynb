{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTE DE HIPER-PARMETROS EN XGBOOST - PARTE 1: CLASIFICACIN\n",
    "\n",
    "Aunque XGBoost es un conjunto de modelos robustos, dise帽ados para reducir el \"overfitting\" en comparaci贸n con los modelos Gradient Boosting, siempre es recomendable ajustar los hiperpar谩metros del modelo para intentar reducir a煤n m谩s su overfitting y a la vez aprovechar al m谩ximo su desempe帽o.\n",
    "\n",
    "El 茅xito de este ajuste de hiper-par谩metros siempre depender谩 tanto de las caracter铆sticas del set de datos que estemos usando como de la misma forma como realicemos el ajuste y esto implica que no necesariamente siempre lograremos mejorar el desempe帽o del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El problema a resolver\n",
    "\n",
    "En esta primera parte de la lecci贸n realizaremos la afinaci贸n de hiper-par谩metros del clasificador XGBoost implementado en la lecci贸n 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estrategia de ajuste sugerida\n",
    "\n",
    "Dado el elevado n煤mero de hiper-par谩metros que se pueden afinar se sugiere 煤nicamente afinar aquellos que usualmente tienen mayor impacto en el desempe帽o ($\\eta$, $\\gamma$, $\\lambda$, m谩xima profundidad de los 谩rboles -'max_depth'- y\n",
    "porcentaje de columnas a usar durante el entrenamiento -'colsample_bytree'-).\n",
    "\n",
    "Teniendo esto en cuenta, la estrategia sugerida es la misma que usamos por ejemplo para afinar los hiper-par谩metros de los 谩rboles de decisi贸n o de los bosques aleatorios, aunque con algunas ligeras diferencias:\n",
    "\n",
    "![](grid-search-clasificacion.png)\n",
    "\n",
    "Aunque podemos usar herramientas como GridSearchCV (vista en detalle en el curso de rboles de Decisi贸n) en este ejemplo veremos la implementaci贸n manual del algoritmo anterior para afinar el modelo de clasificaci贸n implementado en la lecci贸n 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajuste de hiper-par谩metros para clasificaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos leyendo y pre-procesando el mismo set de datos usado en la lecci贸n 6. En este caso usaremos 煤nicamente el set de entrenamiento para afinar los hiper-par谩metros y el set de prueba para, como su nombre lo indica, poner a prueba el modelo afinado con datos totalmente nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19638 entries, 0 to 19637\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   edad                        19638 non-null  float64 \n",
      " 1   genero                      19638 non-null  category\n",
      " 2   educacion                   19638 non-null  category\n",
      " 3   ingresos                    19638 non-null  float64 \n",
      " 4   annos_exp_laboral           19638 non-null  int64   \n",
      " 5   propietario                 19638 non-null  category\n",
      " 6   prestamo_monto_solicitado   19638 non-null  float64 \n",
      " 7   prestamo_uso                19638 non-null  category\n",
      " 8   prestamo_tasa               19638 non-null  float64 \n",
      " 9   prestamo_pctj_ing           19638 non-null  float64 \n",
      " 10  annos_historial_crediticio  19638 non-null  float64 \n",
      " 11  ptj_crediticio              19638 non-null  int64   \n",
      " 12  impagos_previos             19638 non-null  category\n",
      " 13  estado_prestamo             19638 non-null  int64   \n",
      "dtypes: category(5), float64(6), int64(3)\n",
      "memory usage: 1.4 MB\n",
      "Tama帽o set de entrenamiento:  (15710, 13) (15710,)\n",
      "Tama帽o set de prueba:  (3928, 13) (3928,)\n"
     ]
    }
   ],
   "source": [
    "# Leer dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RUTA = '/Users/miguel/Library/CloudStorage/GoogleDrive-miguel@codificandobits.com/My Drive/02-CODIFICANDOBITS.COM/04-Academia/01-Cursos/30-2024-12-XGBoost/data/'\n",
    "df = pd.read_csv(RUTA + 'dataset_prestamos_clasif.csv')\n",
    "\n",
    "# Representar las variables categ贸ricas como tipo \"category\"\n",
    "# (g茅nero, educaci贸n, propietario, prestamo_uso, impagos previos)\n",
    "cols_cat = df.select_dtypes(include='object').columns\n",
    "for col in cols_cat:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Crear sets X y Y y partir dataset\n",
    "X = df.iloc[:,:-1] # Caracter铆sticas (variables predictoras)\n",
    "Y = df.iloc[:,-1] # Variable a predecir\n",
    "\n",
    "# Crear sets de entrenamiento y prueba (la validaci贸n se tomar谩 del set de entrenamiento)\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, Y, train_size=0.8, random_state=123)\n",
    "\n",
    "print('Tama帽o set de entrenamiento: ' , x_tr.shape, y_tr.shape)\n",
    "print('Tama帽o set de prueba: ', x_ts.shape, y_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n implementaremos la funci贸n para realizar la validaci贸n cruzada. En este caso la idea es usar como m茅trica personalizada una proveniente de Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validaci贸n cruzada con m茅trica personalizada y early stopping\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_clf_personalizada(dtrain, custom_metrics, params):\n",
    "    '''Validaci贸n cruzada para clasificaci贸n con early stopping\n",
    "       y m茅trica de desempe帽o personalizada\n",
    "    \n",
    "    Entradas:\n",
    "    - dtrain: datos de entrenamiento en formato DMatrix\n",
    "    - custom_metrics: m茅trica de desempe帽o personalizada\n",
    "    - params: hiper-par谩metros del modelo XGBoost a validar\n",
    "\n",
    "    Salida:\n",
    "    - cv_res: DataFrame de Pandas con los resultados de la validaci贸n\n",
    "    '''\n",
    "\n",
    "    cv_res = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,           # N煤mero inicial de 谩rboles a entrenar\n",
    "        early_stopping_rounds=10,       # Criterio de parada temprana con base en la m茅trica personalizada\n",
    "        nfold=5,                        # N煤mero de particiones\n",
    "        seed=123,                       # Semilla generador aleatorio\n",
    "        custom_metric=custom_metrics,   # *** MTRICA DE EVALUACIN PERSONALIZADA ***\n",
    "        maximize=True,                  # Maximizar la exactitud\n",
    "        as_pandas=True                  # Retornar resultados como DataFrame de Pandas\n",
    "    )\n",
    "\n",
    "    return cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y usemos la funci贸n anterior para crear un modelo base y estimar su desempe帽o. Este modelo base nos servir谩 como referencia para determinar si el modelo afinado tiene o no un mejor desempe帽o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESEMPEO MODELO BASE - VALIDACIN CRUZADA: \n",
      "==================================================\n",
      "   Exactitud train: 92.8%\n",
      "   Exactitud test: 90.4%\n"
     ]
    }
   ],
   "source": [
    "# Calcular e imprimir en pantalla desempe帽o modelo base\n",
    "\n",
    "# Modelo base\n",
    "parametros = {\n",
    "    'booster': 'gbtree',           # Usar 谩rboles tipo gradient boosting\n",
    "    'eta': 0.1,                    # Tasa de aprendizaje\n",
    "    'gamma': 0,\n",
    "    'lambda': 0,\n",
    "    'max_depth': 6,                # Profundidad m谩xima de los 谩rboles\n",
    "    'colsample_bytree': 0.8,       # Porcentaje de columnas a muestrear\n",
    "    'objective': 'binary:logistic',# P茅rdida\n",
    "    'random_state': 42             # Semilla generador aleatorio\n",
    "    }\n",
    "\n",
    "# M茅trica personalizada\n",
    "def custom_metrics_clf(preds, dtrain):\n",
    "    labels = dtrain.get_label()  # Valores a predecir\n",
    "    preds_binary = [1 if p > 0.5 else 0 for p in preds]  # De probabilidades a predicciones\n",
    "    acc = accuracy_score(labels, preds_binary)\n",
    "    return 'exactitud', acc  # Retornar el nombre y el valor de la m茅trica\n",
    "\n",
    "# CV personalizada\n",
    "dtrain = xgb.DMatrix(data=x_tr, label=y_tr, enable_categorical=True)\n",
    "cv_res = cv_clf_personalizada(dtrain, custom_metrics=custom_metrics_clf, params = parametros)\n",
    "\n",
    "# Imprimir en pantalla\n",
    "best_round = cv_res['test-exactitud-mean'].idxmax()\n",
    "clf_base_train = cv_res['train-exactitud-mean'].iloc[best_round]\n",
    "clf_base_test = cv_res['test-exactitud-mean'].iloc[best_round]\n",
    "\n",
    "print('DESEMPEO MODELO BASE - VALIDACIN CRUZADA: ')\n",
    "print('='*50)\n",
    "print(f'   Exactitud train: {100*clf_base_train:.1f}%')\n",
    "print(f'   Exactitud test: {100*clf_base_test:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora implementaremos la funci贸n para realizar la afinaci贸n de hiper-par谩metros, haciendo uso de la validaci贸n cruzada implementada anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n para afinar hiper-par谩metros\n",
    "from sklearn.model_selection import ParameterGrid # Para obtener todas las combinaciones de hiper-par谩metros\n",
    "\n",
    "def afinar_hiperparams_clf(dtrain, grilla, parametros, custom_metrics):\n",
    "    '''Ajuste de hiper-par谩metros usando b煤squeda exhaustiva (Grid Search)\n",
    "    \n",
    "    Entradas:\n",
    "    - dtrain: datos de entrenamiento en formato DMatrix\n",
    "    - grilla: grilla de hiper-par谩metros definida por el usuario\n",
    "    - parametros: hiper-par谩metros del modelo XGBoost que no ser谩n ajustados\n",
    "    - custom_metrics: m茅trica de desempe帽o personalizada\n",
    "\n",
    "    Salida:\n",
    "    - mejor_puntaje: mejor m茅trica de desempe帽o obtenida tras la afinaci贸n\n",
    "    - mejores_hiperparams: mejor conjunto de hiper-par谩metros obtenido tras la afinaci贸n  \n",
    "    '''\n",
    "    \n",
    "    # 1. Inicializar mejores hiper-par谩metros y mejor puntaje (exactitud)\n",
    "    mejores_hparams = None\n",
    "    mejor_puntaje = 0\n",
    "\n",
    "    # 2. Realizar ajuste de hiper-par谩metros\n",
    "    N = len(ParameterGrid(grilla))\n",
    "\n",
    "    for i, combinacion in enumerate(ParameterGrid(grilla)):\n",
    "        print(f'Combinaci贸n {i+1}/{N}...')\n",
    "\n",
    "        # Definir hiper-par谩metros\n",
    "        params = combinacion | parametros\n",
    "\n",
    "        # Validaci贸n cruzada con early-stopping y m茅trica \"accuracy\"\n",
    "        cv_res = cv_clf_personalizada(dtrain, custom_metrics, params=params)\n",
    "\n",
    "        # Extraer mejor desempe帽o para los \"folds\" de prueba\n",
    "        puntaje_set_prueba = cv_res['test-exactitud-mean'].max()\n",
    "\n",
    "        if puntaje_set_prueba > mejor_puntaje:\n",
    "            mejor_puntaje = puntaje_set_prueba\n",
    "            mejores_hparams = combinacion\n",
    "            print(f'    Mejor puntaje hasta el momento (folds de prueba): {mejor_puntaje:.5f}')\n",
    "        \n",
    "    # Retornar mejor puntaje y mejores hiper-par谩metros\n",
    "    return mejor_puntaje, mejores_hparams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y en este punto ya estamos listos para realizar la afinaci贸n de hiper-par谩metros. Simplemente creamos la grilla de hiper-par谩metros y definimos igualmente los hiper-par谩metros que NO se afinar谩n, e introducimos ambos como argumentos de la funci贸n anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaci贸n 1/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90560\n",
      "Combinaci贸n 2/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90757\n",
      "Combinaci贸n 3/243...\n",
      "Combinaci贸n 4/243...\n",
      "Combinaci贸n 5/243...\n",
      "Combinaci贸n 6/243...\n",
      "Combinaci贸n 7/243...\n",
      "Combinaci贸n 8/243...\n",
      "Combinaci贸n 9/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90764\n",
      "Combinaci贸n 10/243...\n",
      "Combinaci贸n 11/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90827\n",
      "Combinaci贸n 12/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90898\n",
      "Combinaci贸n 13/243...\n",
      "Combinaci贸n 14/243...\n",
      "Combinaci贸n 15/243...\n",
      "Combinaci贸n 16/243...\n",
      "Combinaci贸n 17/243...\n",
      "Combinaci贸n 18/243...\n",
      "Combinaci贸n 19/243...\n",
      "Combinaci贸n 20/243...\n",
      "Combinaci贸n 21/243...\n",
      "Combinaci贸n 22/243...\n",
      "Combinaci贸n 23/243...\n",
      "Combinaci贸n 24/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90987\n",
      "Combinaci贸n 25/243...\n",
      "Combinaci贸n 26/243...\n",
      "Combinaci贸n 27/243...\n",
      "Combinaci贸n 28/243...\n",
      "Combinaci贸n 29/243...\n",
      "Combinaci贸n 30/243...\n",
      "Combinaci贸n 31/243...\n",
      "Combinaci贸n 32/243...\n",
      "Combinaci贸n 33/243...\n",
      "Combinaci贸n 34/243...\n",
      "Combinaci贸n 35/243...\n",
      "Combinaci贸n 36/243...\n",
      "Combinaci贸n 37/243...\n",
      "Combinaci贸n 38/243...\n",
      "Combinaci贸n 39/243...\n",
      "Combinaci贸n 40/243...\n",
      "Combinaci贸n 41/243...\n",
      "Combinaci贸n 42/243...\n",
      "Combinaci贸n 43/243...\n",
      "Combinaci贸n 44/243...\n",
      "Combinaci贸n 45/243...\n",
      "Combinaci贸n 46/243...\n",
      "Combinaci贸n 47/243...\n",
      "Combinaci贸n 48/243...\n",
      "Combinaci贸n 49/243...\n",
      "Combinaci贸n 50/243...\n",
      "Combinaci贸n 51/243...\n",
      "Combinaci贸n 52/243...\n",
      "Combinaci贸n 53/243...\n",
      "Combinaci贸n 54/243...\n",
      "Combinaci贸n 55/243...\n",
      "Combinaci贸n 56/243...\n",
      "Combinaci贸n 57/243...\n",
      "Combinaci贸n 58/243...\n",
      "Combinaci贸n 59/243...\n",
      "Combinaci贸n 60/243...\n",
      "Combinaci贸n 61/243...\n",
      "Combinaci贸n 62/243...\n",
      "Combinaci贸n 63/243...\n",
      "Combinaci贸n 64/243...\n",
      "Combinaci贸n 65/243...\n",
      "Combinaci贸n 66/243...\n",
      "Combinaci贸n 67/243...\n",
      "Combinaci贸n 68/243...\n",
      "Combinaci贸n 69/243...\n",
      "Combinaci贸n 70/243...\n",
      "Combinaci贸n 71/243...\n",
      "Combinaci贸n 72/243...\n",
      "Combinaci贸n 73/243...\n",
      "Combinaci贸n 74/243...\n",
      "Combinaci贸n 75/243...\n",
      "Combinaci贸n 76/243...\n",
      "Combinaci贸n 77/243...\n",
      "Combinaci贸n 78/243...\n",
      "Combinaci贸n 79/243...\n",
      "Combinaci贸n 80/243...\n",
      "Combinaci贸n 81/243...\n",
      "Combinaci贸n 82/243...\n",
      "Combinaci贸n 83/243...\n",
      "Combinaci贸n 84/243...\n",
      "Combinaci贸n 85/243...\n",
      "Combinaci贸n 86/243...\n",
      "Combinaci贸n 87/243...\n",
      "Combinaci贸n 88/243...\n",
      "Combinaci贸n 89/243...\n",
      "Combinaci贸n 90/243...\n",
      "Combinaci贸n 91/243...\n",
      "Combinaci贸n 92/243...\n",
      "Combinaci贸n 93/243...\n",
      "Combinaci贸n 94/243...\n",
      "Combinaci贸n 95/243...\n",
      "Combinaci贸n 96/243...\n",
      "Combinaci贸n 97/243...\n",
      "Combinaci贸n 98/243...\n",
      "Combinaci贸n 99/243...\n",
      "Combinaci贸n 100/243...\n",
      "Combinaci贸n 101/243...\n",
      "Combinaci贸n 102/243...\n",
      "Combinaci贸n 103/243...\n",
      "Combinaci贸n 104/243...\n",
      "Combinaci贸n 105/243...\n",
      "Combinaci贸n 106/243...\n",
      "Combinaci贸n 107/243...\n",
      "Combinaci贸n 108/243...\n",
      "Combinaci贸n 109/243...\n",
      "Combinaci贸n 110/243...\n",
      "Combinaci贸n 111/243...\n",
      "Combinaci贸n 112/243...\n",
      "Combinaci贸n 113/243...\n",
      "Combinaci贸n 114/243...\n",
      "Combinaci贸n 115/243...\n",
      "Combinaci贸n 116/243...\n",
      "Combinaci贸n 117/243...\n",
      "Combinaci贸n 118/243...\n",
      "Combinaci贸n 119/243...\n",
      "Combinaci贸n 120/243...\n",
      "Combinaci贸n 121/243...\n",
      "Combinaci贸n 122/243...\n",
      "Combinaci贸n 123/243...\n",
      "Combinaci贸n 124/243...\n",
      "Combinaci贸n 125/243...\n",
      "Combinaci贸n 126/243...\n",
      "Combinaci贸n 127/243...\n",
      "Combinaci贸n 128/243...\n",
      "Combinaci贸n 129/243...\n",
      "Combinaci贸n 130/243...\n",
      "Combinaci贸n 131/243...\n",
      "Combinaci贸n 132/243...\n",
      "Combinaci贸n 133/243...\n",
      "Combinaci贸n 134/243...\n",
      "Combinaci贸n 135/243...\n",
      "Combinaci贸n 136/243...\n",
      "Combinaci贸n 137/243...\n",
      "Combinaci贸n 138/243...\n",
      "Combinaci贸n 139/243...\n",
      "Combinaci贸n 140/243...\n",
      "Combinaci贸n 141/243...\n",
      "Combinaci贸n 142/243...\n",
      "Combinaci贸n 143/243...\n",
      "Combinaci贸n 144/243...\n",
      "Combinaci贸n 145/243...\n",
      "Combinaci贸n 146/243...\n",
      "Combinaci贸n 147/243...\n",
      "Combinaci贸n 148/243...\n",
      "Combinaci贸n 149/243...\n",
      "Combinaci贸n 150/243...\n",
      "Combinaci贸n 151/243...\n",
      "Combinaci贸n 152/243...\n",
      "Combinaci贸n 153/243...\n",
      "Combinaci贸n 154/243...\n",
      "Combinaci贸n 155/243...\n",
      "Combinaci贸n 156/243...\n",
      "Combinaci贸n 157/243...\n",
      "Combinaci贸n 158/243...\n",
      "Combinaci贸n 159/243...\n",
      "Combinaci贸n 160/243...\n",
      "Combinaci贸n 161/243...\n",
      "Combinaci贸n 162/243...\n",
      "Combinaci贸n 163/243...\n",
      "Combinaci贸n 164/243...\n",
      "Combinaci贸n 165/243...\n",
      "Combinaci贸n 166/243...\n",
      "Combinaci贸n 167/243...\n",
      "Combinaci贸n 168/243...\n",
      "Combinaci贸n 169/243...\n",
      "Combinaci贸n 170/243...\n",
      "Combinaci贸n 171/243...\n",
      "Combinaci贸n 172/243...\n",
      "Combinaci贸n 173/243...\n",
      "Combinaci贸n 174/243...\n",
      "Combinaci贸n 175/243...\n",
      "Combinaci贸n 176/243...\n",
      "Combinaci贸n 177/243...\n",
      "Combinaci贸n 178/243...\n",
      "Combinaci贸n 179/243...\n",
      "Combinaci贸n 180/243...\n",
      "Combinaci贸n 181/243...\n",
      "Combinaci贸n 182/243...\n",
      "Combinaci贸n 183/243...\n",
      "Combinaci贸n 184/243...\n",
      "Combinaci贸n 185/243...\n",
      "Combinaci贸n 186/243...\n",
      "Combinaci贸n 187/243...\n",
      "Combinaci贸n 188/243...\n",
      "Combinaci贸n 189/243...\n",
      "Combinaci贸n 190/243...\n",
      "Combinaci贸n 191/243...\n",
      "Combinaci贸n 192/243...\n",
      "Combinaci贸n 193/243...\n",
      "Combinaci贸n 194/243...\n",
      "Combinaci贸n 195/243...\n",
      "Combinaci贸n 196/243...\n",
      "Combinaci贸n 197/243...\n",
      "Combinaci贸n 198/243...\n",
      "Combinaci贸n 199/243...\n",
      "Combinaci贸n 200/243...\n",
      "Combinaci贸n 201/243...\n",
      "Combinaci贸n 202/243...\n",
      "Combinaci贸n 203/243...\n",
      "Combinaci贸n 204/243...\n",
      "Combinaci贸n 205/243...\n",
      "Combinaci贸n 206/243...\n",
      "Combinaci贸n 207/243...\n",
      "Combinaci贸n 208/243...\n",
      "Combinaci贸n 209/243...\n",
      "Combinaci贸n 210/243...\n",
      "Combinaci贸n 211/243...\n",
      "Combinaci贸n 212/243...\n",
      "Combinaci贸n 213/243...\n",
      "Combinaci贸n 214/243...\n",
      "Combinaci贸n 215/243...\n",
      "Combinaci贸n 216/243...\n",
      "Combinaci贸n 217/243...\n",
      "Combinaci贸n 218/243...\n",
      "Combinaci贸n 219/243...\n",
      "Combinaci贸n 220/243...\n",
      "Combinaci贸n 221/243...\n",
      "Combinaci贸n 222/243...\n",
      "Combinaci贸n 223/243...\n",
      "Combinaci贸n 224/243...\n",
      "Combinaci贸n 225/243...\n",
      "Combinaci贸n 226/243...\n",
      "Combinaci贸n 227/243...\n",
      "Combinaci贸n 228/243...\n",
      "Combinaci贸n 229/243...\n",
      "Combinaci贸n 230/243...\n",
      "Combinaci贸n 231/243...\n",
      "Combinaci贸n 232/243...\n",
      "Combinaci贸n 233/243...\n",
      "Combinaci贸n 234/243...\n",
      "Combinaci贸n 235/243...\n",
      "Combinaci贸n 236/243...\n",
      "Combinaci贸n 237/243...\n",
      "Combinaci贸n 238/243...\n",
      "Combinaci贸n 239/243...\n",
      "Combinaci贸n 240/243...\n",
      "Combinaci贸n 241/243...\n",
      "Combinaci贸n 242/243...\n",
      "Combinaci贸n 243/243...\n",
      "Mejores hiper-par谩metros: {'colsample_bytree': 0.7, 'eta': 0.4, 'gamma': 0.2, 'lambda': 2, 'max_depth': 4}\n",
      "Mejor exactitud: 91.0%\n"
     ]
    }
   ],
   "source": [
    "# Realizar afinaci贸n con la funci贸n anterior\n",
    "# Crear grilla de hiper-par谩metros\n",
    "grilla_hparams = {\n",
    "    'eta': [0.4, 0.5, 0.6],     # Tasas de aprendizaje\n",
    "    'gamma': [0, 0.1, 0.2],     # Hiper-par谩metro \n",
    "    'lambda': [1.5, 2, 2.5],    # Hiper-par谩metro 位\n",
    "    'max_depth': [2, 3, 4],     # M谩xima profundidad del 谩rbol\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9], # Porcentaje de muestreo de las columnas\n",
    "}\n",
    "\n",
    "# Par谩metros que no se ajustar谩n\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 42,   \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "best_score, best_params = afinar_hiperparams_clf(dtrain, grilla_hparams, params, custom_metrics_clf)\n",
    "\n",
    "# Imprimir mejores hiper-par谩metros y mejor puntaje\n",
    "print(\"Mejores hiper-par谩metros:\", best_params)\n",
    "print(\"Mejor exactitud:\", f'{100*best_score:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora estimaremos el desempe帽o del modelo afinado tanto para entrenamiento como para prueba usando la funci贸n para realizar la validaci贸n cruzada. En este caso usaremos como par谩metros tanto los par谩metros que no se afinan como los mejores hiper-par谩metros que acabamos de encontrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESEMPEO MODELO AFINADO - VALIDACIN CRUZADA: \n",
      "==================================================\n",
      "   Exactitud train: 94.6%\n",
      "   Exactitud test: 91.0%\n"
     ]
    }
   ],
   "source": [
    "# Mostrar desempe帽o del modelo afinado\n",
    "\n",
    "# Modelo afinado\n",
    "parametros = best_params | params\n",
    "\n",
    "# CV personalizada\n",
    "cv_res = cv_clf_personalizada(dtrain, custom_metrics_clf, params = parametros)\n",
    "\n",
    "# Imprimir en pantalla\n",
    "best_round = cv_res['test-exactitud-mean'].idxmax()\n",
    "clf_afinado_train = cv_res['train-exactitud-mean'].iloc[best_round]\n",
    "clf_afinado_test = cv_res['test-exactitud-mean'].iloc[best_round]\n",
    "\n",
    "print('DESEMPEO MODELO AFINADO - VALIDACIN CRUZADA: ')\n",
    "print('='*50)\n",
    "print(f'   Exactitud train: {100*clf_afinado_train:.1f}%')\n",
    "print(f'   Exactitud test: {100*clf_afinado_test:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y hemos logrado pasar de un modelo con desempe帽o entrenamiento/prueba 92.8%/90.4% a uno con desempe帽o de 94.6%/91.0%.\n",
    "\n",
    "Aunque esta afinaci贸n ha incrementado el desempe帽o con los datos de prueba tambi茅n ha incrementado ligeramente el \"overfitting\" y esto se podr铆a mejorar probando con una grilla hiper-par谩metros m谩s amplia.\n",
    "\n",
    "Sin embargo, tambi茅n debemos tener en cuenta que el incremento en el desempe帽o (90.4% a 91.0%) ha sido marginal y esto muestra que XGBoost es realmente un modelo robusto y que, generalmente, las mejoras tras la afinaci贸n de hiper-par谩metros ser谩n marginales.\n",
    "\n",
    "Por 煤ltimo, podemos entrenar el modelo afinado y generar predicciones con datos totalmente nuevos (el set de prueba, que no hemos usado hasta el momento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar modelo afinado\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = parametros | {'enable_categorical':True}\n",
    "clf_afinado = XGBClassifier(**params)\n",
    "clf_afinado.fit(x_tr,y_tr) # Se recomienda agregar early stopping\n",
    "\n",
    "# Y generar predicciones sobre datos nuevos\n",
    "preds = clf_afinado.predict(x_ts)\n",
    "preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
