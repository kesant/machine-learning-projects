{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTE DE HIPER-PARÁMETROS EN XGBOOST - PARTE 1: CLASIFICACIÓN\n",
    "\n",
    "Aunque XGBoost es un conjunto de modelos robustos, diseñados para reducir el \"overfitting\" en comparación con los modelos Gradient Boosting, siempre es recomendable ajustar los hiperparámetros del modelo para intentar reducir aún más su overfitting y a la vez aprovechar al máximo su desempeño.\n",
    "\n",
    "El éxito de este ajuste de hiper-parámetros siempre dependerá tanto de las características del set de datos que estemos usando como de la misma forma como realicemos el ajuste y esto implica que no necesariamente siempre lograremos mejorar el desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El problema a resolver\n",
    "\n",
    "En esta primera parte de la lección realizaremos la afinación de hiper-parámetros del clasificador XGBoost implementado en la lección 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estrategia de ajuste sugerida\n",
    "\n",
    "Dado el elevado número de hiper-parámetros que se pueden afinar se sugiere únicamente afinar aquellos que usualmente tienen mayor impacto en el desempeño ($\\eta$, $\\gamma$, $\\lambda$, máxima profundidad de los árboles -'max_depth'- y\n",
    "porcentaje de columnas a usar durante el entrenamiento -'colsample_bytree'-).\n",
    "\n",
    "Teniendo esto en cuenta, la estrategia sugerida es la misma que usamos por ejemplo para afinar los hiper-parámetros de los árboles de decisión o de los bosques aleatorios, aunque con algunas ligeras diferencias:\n",
    "\n",
    "![](grid-search-clasificacion.png)\n",
    "\n",
    "Aunque podemos usar herramientas como GridSearchCV (vista en detalle en el curso de Árboles de Decisión) en este ejemplo veremos la implementación manual del algoritmo anterior para afinar el modelo de clasificación implementado en la lección 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajuste de hiper-parámetros para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos leyendo y pre-procesando el mismo set de datos usado en la lección 6. En este caso usaremos únicamente el set de entrenamiento para afinar los hiper-parámetros y el set de prueba para, como su nombre lo indica, poner a prueba el modelo afinado con datos totalmente nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19638 entries, 0 to 19637\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   edad                        19638 non-null  float64 \n",
      " 1   genero                      19638 non-null  category\n",
      " 2   educacion                   19638 non-null  category\n",
      " 3   ingresos                    19638 non-null  float64 \n",
      " 4   annos_exp_laboral           19638 non-null  int64   \n",
      " 5   propietario                 19638 non-null  category\n",
      " 6   prestamo_monto_solicitado   19638 non-null  float64 \n",
      " 7   prestamo_uso                19638 non-null  category\n",
      " 8   prestamo_tasa               19638 non-null  float64 \n",
      " 9   prestamo_pctj_ing           19638 non-null  float64 \n",
      " 10  annos_historial_crediticio  19638 non-null  float64 \n",
      " 11  ptj_crediticio              19638 non-null  int64   \n",
      " 12  impagos_previos             19638 non-null  category\n",
      " 13  estado_prestamo             19638 non-null  int64   \n",
      "dtypes: category(5), float64(6), int64(3)\n",
      "memory usage: 1.4 MB\n",
      "Tamaño set de entrenamiento:  (15710, 13) (15710,)\n",
      "Tamaño set de prueba:  (3928, 13) (3928,)\n"
     ]
    }
   ],
   "source": [
    "# Leer dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RUTA = '/Users/miguel/Library/CloudStorage/GoogleDrive-miguel@codificandobits.com/My Drive/02-CODIFICANDOBITS.COM/04-Academia/01-Cursos/30-2024-12-XGBoost/data/'\n",
    "df = pd.read_csv(RUTA + 'dataset_prestamos_clasif.csv')\n",
    "\n",
    "# Representar las variables categóricas como tipo \"category\"\n",
    "# (género, educación, propietario, prestamo_uso, impagos previos)\n",
    "cols_cat = df.select_dtypes(include='object').columns\n",
    "for col in cols_cat:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Crear sets X y Y y partir dataset\n",
    "X = df.iloc[:,:-1] # Características (variables predictoras)\n",
    "Y = df.iloc[:,-1] # Variable a predecir\n",
    "\n",
    "# Crear sets de entrenamiento y prueba (la validación se tomará del set de entrenamiento)\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, Y, train_size=0.8, random_state=123)\n",
    "\n",
    "print('Tamaño set de entrenamiento: ' , x_tr.shape, y_tr.shape)\n",
    "print('Tamaño set de prueba: ', x_ts.shape, y_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación implementaremos la función para realizar la validación cruzada. En este caso la idea es usar como métrica personalizada una proveniente de Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada con métrica personalizada y early stopping\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_clf_personalizada(dtrain, custom_metrics, params):\n",
    "    '''Validación cruzada para clasificación con early stopping\n",
    "       y métrica de desempeño personalizada\n",
    "    \n",
    "    Entradas:\n",
    "    - dtrain: datos de entrenamiento en formato DMatrix\n",
    "    - custom_metrics: métrica de desempeño personalizada\n",
    "    - params: hiper-parámetros del modelo XGBoost a validar\n",
    "\n",
    "    Salida:\n",
    "    - cv_res: DataFrame de Pandas con los resultados de la validación\n",
    "    '''\n",
    "\n",
    "    cv_res = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,           # Número inicial de árboles a entrenar\n",
    "        early_stopping_rounds=10,       # Criterio de parada temprana con base en la métrica personalizada\n",
    "        nfold=5,                        # Número de particiones\n",
    "        seed=123,                       # Semilla generador aleatorio\n",
    "        custom_metric=custom_metrics,   # *** MÉTRICA DE EVALUACIÓN PERSONALIZADA ***\n",
    "        maximize=True,                  # Maximizar la exactitud\n",
    "        as_pandas=True                  # Retornar resultados como DataFrame de Pandas\n",
    "    )\n",
    "\n",
    "    return cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y usemos la función anterior para crear un modelo base y estimar su desempeño. Este modelo base nos servirá como referencia para determinar si el modelo afinado tiene o no un mejor desempeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESEMPEÑO MODELO BASE - VALIDACIÓN CRUZADA: \n",
      "==================================================\n",
      "   Exactitud train: 92.8%\n",
      "   Exactitud test: 90.4%\n"
     ]
    }
   ],
   "source": [
    "# Calcular e imprimir en pantalla desempeño modelo base\n",
    "\n",
    "# Modelo base\n",
    "parametros = {\n",
    "    'booster': 'gbtree',           # Usar árboles tipo gradient boosting\n",
    "    'eta': 0.1,                    # Tasa de aprendizaje\n",
    "    'gamma': 0,\n",
    "    'lambda': 0,\n",
    "    'max_depth': 6,                # Profundidad máxima de los árboles\n",
    "    'colsample_bytree': 0.8,       # Porcentaje de columnas a muestrear\n",
    "    'objective': 'binary:logistic',# Pérdida\n",
    "    'random_state': 42             # Semilla generador aleatorio\n",
    "    }\n",
    "\n",
    "# Métrica personalizada\n",
    "def custom_metrics_clf(preds, dtrain):\n",
    "    labels = dtrain.get_label()  # Valores a predecir\n",
    "    preds_binary = [1 if p > 0.5 else 0 for p in preds]  # De probabilidades a predicciones\n",
    "    acc = accuracy_score(labels, preds_binary)\n",
    "    return 'exactitud', acc  # Retornar el nombre y el valor de la métrica\n",
    "\n",
    "# CV personalizada\n",
    "dtrain = xgb.DMatrix(data=x_tr, label=y_tr, enable_categorical=True)\n",
    "cv_res = cv_clf_personalizada(dtrain, custom_metrics=custom_metrics_clf, params = parametros)\n",
    "\n",
    "# Imprimir en pantalla\n",
    "best_round = cv_res['test-exactitud-mean'].idxmax()\n",
    "clf_base_train = cv_res['train-exactitud-mean'].iloc[best_round]\n",
    "clf_base_test = cv_res['test-exactitud-mean'].iloc[best_round]\n",
    "\n",
    "print('DESEMPEÑO MODELO BASE - VALIDACIÓN CRUZADA: ')\n",
    "print('='*50)\n",
    "print(f'   Exactitud train: {100*clf_base_train:.1f}%')\n",
    "print(f'   Exactitud test: {100*clf_base_test:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora implementaremos la función para realizar la afinación de hiper-parámetros, haciendo uso de la validación cruzada implementada anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para afinar hiper-parámetros\n",
    "from sklearn.model_selection import ParameterGrid # Para obtener todas las combinaciones de hiper-parámetros\n",
    "\n",
    "def afinar_hiperparams_clf(dtrain, grilla, parametros, custom_metrics):\n",
    "    '''Ajuste de hiper-parámetros usando búsqueda exhaustiva (Grid Search)\n",
    "    \n",
    "    Entradas:\n",
    "    - dtrain: datos de entrenamiento en formato DMatrix\n",
    "    - grilla: grilla de hiper-parámetros definida por el usuario\n",
    "    - parametros: hiper-parámetros del modelo XGBoost que no serán ajustados\n",
    "    - custom_metrics: métrica de desempeño personalizada\n",
    "\n",
    "    Salida:\n",
    "    - mejor_puntaje: mejor métrica de desempeño obtenida tras la afinación\n",
    "    - mejores_hiperparams: mejor conjunto de hiper-parámetros obtenido tras la afinación  \n",
    "    '''\n",
    "    \n",
    "    # 1. Inicializar mejores hiper-parámetros y mejor puntaje (exactitud)\n",
    "    mejores_hparams = None\n",
    "    mejor_puntaje = 0\n",
    "\n",
    "    # 2. Realizar ajuste de hiper-parámetros\n",
    "    N = len(ParameterGrid(grilla))\n",
    "\n",
    "    for i, combinacion in enumerate(ParameterGrid(grilla)):\n",
    "        print(f'Combinación {i+1}/{N}...')\n",
    "\n",
    "        # Definir hiper-parámetros\n",
    "        params = combinacion | parametros\n",
    "\n",
    "        # Validación cruzada con early-stopping y métrica \"accuracy\"\n",
    "        cv_res = cv_clf_personalizada(dtrain, custom_metrics, params=params)\n",
    "\n",
    "        # Extraer mejor desempeño para los \"folds\" de prueba\n",
    "        puntaje_set_prueba = cv_res['test-exactitud-mean'].max()\n",
    "\n",
    "        if puntaje_set_prueba > mejor_puntaje:\n",
    "            mejor_puntaje = puntaje_set_prueba\n",
    "            mejores_hparams = combinacion\n",
    "            print(f'    Mejor puntaje hasta el momento (folds de prueba): {mejor_puntaje:.5f}')\n",
    "        \n",
    "    # Retornar mejor puntaje y mejores hiper-parámetros\n",
    "    return mejor_puntaje, mejores_hparams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y en este punto ya estamos listos para realizar la afinación de hiper-parámetros. Simplemente creamos la grilla de hiper-parámetros y definimos igualmente los hiper-parámetros que NO se afinarán, e introducimos ambos como argumentos de la función anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinación 1/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90560\n",
      "Combinación 2/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90757\n",
      "Combinación 3/243...\n",
      "Combinación 4/243...\n",
      "Combinación 5/243...\n",
      "Combinación 6/243...\n",
      "Combinación 7/243...\n",
      "Combinación 8/243...\n",
      "Combinación 9/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90764\n",
      "Combinación 10/243...\n",
      "Combinación 11/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90827\n",
      "Combinación 12/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90898\n",
      "Combinación 13/243...\n",
      "Combinación 14/243...\n",
      "Combinación 15/243...\n",
      "Combinación 16/243...\n",
      "Combinación 17/243...\n",
      "Combinación 18/243...\n",
      "Combinación 19/243...\n",
      "Combinación 20/243...\n",
      "Combinación 21/243...\n",
      "Combinación 22/243...\n",
      "Combinación 23/243...\n",
      "Combinación 24/243...\n",
      "    Mejor puntaje hasta el momento (folds de prueba): 0.90987\n",
      "Combinación 25/243...\n",
      "Combinación 26/243...\n",
      "Combinación 27/243...\n",
      "Combinación 28/243...\n",
      "Combinación 29/243...\n",
      "Combinación 30/243...\n",
      "Combinación 31/243...\n",
      "Combinación 32/243...\n",
      "Combinación 33/243...\n",
      "Combinación 34/243...\n",
      "Combinación 35/243...\n",
      "Combinación 36/243...\n",
      "Combinación 37/243...\n",
      "Combinación 38/243...\n",
      "Combinación 39/243...\n",
      "Combinación 40/243...\n",
      "Combinación 41/243...\n",
      "Combinación 42/243...\n",
      "Combinación 43/243...\n",
      "Combinación 44/243...\n",
      "Combinación 45/243...\n",
      "Combinación 46/243...\n",
      "Combinación 47/243...\n",
      "Combinación 48/243...\n",
      "Combinación 49/243...\n",
      "Combinación 50/243...\n",
      "Combinación 51/243...\n",
      "Combinación 52/243...\n",
      "Combinación 53/243...\n",
      "Combinación 54/243...\n",
      "Combinación 55/243...\n",
      "Combinación 56/243...\n",
      "Combinación 57/243...\n",
      "Combinación 58/243...\n",
      "Combinación 59/243...\n",
      "Combinación 60/243...\n",
      "Combinación 61/243...\n",
      "Combinación 62/243...\n",
      "Combinación 63/243...\n",
      "Combinación 64/243...\n",
      "Combinación 65/243...\n",
      "Combinación 66/243...\n",
      "Combinación 67/243...\n",
      "Combinación 68/243...\n",
      "Combinación 69/243...\n",
      "Combinación 70/243...\n",
      "Combinación 71/243...\n",
      "Combinación 72/243...\n",
      "Combinación 73/243...\n",
      "Combinación 74/243...\n",
      "Combinación 75/243...\n",
      "Combinación 76/243...\n",
      "Combinación 77/243...\n",
      "Combinación 78/243...\n",
      "Combinación 79/243...\n",
      "Combinación 80/243...\n",
      "Combinación 81/243...\n",
      "Combinación 82/243...\n",
      "Combinación 83/243...\n",
      "Combinación 84/243...\n",
      "Combinación 85/243...\n",
      "Combinación 86/243...\n",
      "Combinación 87/243...\n",
      "Combinación 88/243...\n",
      "Combinación 89/243...\n",
      "Combinación 90/243...\n",
      "Combinación 91/243...\n",
      "Combinación 92/243...\n",
      "Combinación 93/243...\n",
      "Combinación 94/243...\n",
      "Combinación 95/243...\n",
      "Combinación 96/243...\n",
      "Combinación 97/243...\n",
      "Combinación 98/243...\n",
      "Combinación 99/243...\n",
      "Combinación 100/243...\n",
      "Combinación 101/243...\n",
      "Combinación 102/243...\n",
      "Combinación 103/243...\n",
      "Combinación 104/243...\n",
      "Combinación 105/243...\n",
      "Combinación 106/243...\n",
      "Combinación 107/243...\n",
      "Combinación 108/243...\n",
      "Combinación 109/243...\n",
      "Combinación 110/243...\n",
      "Combinación 111/243...\n",
      "Combinación 112/243...\n",
      "Combinación 113/243...\n",
      "Combinación 114/243...\n",
      "Combinación 115/243...\n",
      "Combinación 116/243...\n",
      "Combinación 117/243...\n",
      "Combinación 118/243...\n",
      "Combinación 119/243...\n",
      "Combinación 120/243...\n",
      "Combinación 121/243...\n",
      "Combinación 122/243...\n",
      "Combinación 123/243...\n",
      "Combinación 124/243...\n",
      "Combinación 125/243...\n",
      "Combinación 126/243...\n",
      "Combinación 127/243...\n",
      "Combinación 128/243...\n",
      "Combinación 129/243...\n",
      "Combinación 130/243...\n",
      "Combinación 131/243...\n",
      "Combinación 132/243...\n",
      "Combinación 133/243...\n",
      "Combinación 134/243...\n",
      "Combinación 135/243...\n",
      "Combinación 136/243...\n",
      "Combinación 137/243...\n",
      "Combinación 138/243...\n",
      "Combinación 139/243...\n",
      "Combinación 140/243...\n",
      "Combinación 141/243...\n",
      "Combinación 142/243...\n",
      "Combinación 143/243...\n",
      "Combinación 144/243...\n",
      "Combinación 145/243...\n",
      "Combinación 146/243...\n",
      "Combinación 147/243...\n",
      "Combinación 148/243...\n",
      "Combinación 149/243...\n",
      "Combinación 150/243...\n",
      "Combinación 151/243...\n",
      "Combinación 152/243...\n",
      "Combinación 153/243...\n",
      "Combinación 154/243...\n",
      "Combinación 155/243...\n",
      "Combinación 156/243...\n",
      "Combinación 157/243...\n",
      "Combinación 158/243...\n",
      "Combinación 159/243...\n",
      "Combinación 160/243...\n",
      "Combinación 161/243...\n",
      "Combinación 162/243...\n",
      "Combinación 163/243...\n",
      "Combinación 164/243...\n",
      "Combinación 165/243...\n",
      "Combinación 166/243...\n",
      "Combinación 167/243...\n",
      "Combinación 168/243...\n",
      "Combinación 169/243...\n",
      "Combinación 170/243...\n",
      "Combinación 171/243...\n",
      "Combinación 172/243...\n",
      "Combinación 173/243...\n",
      "Combinación 174/243...\n",
      "Combinación 175/243...\n",
      "Combinación 176/243...\n",
      "Combinación 177/243...\n",
      "Combinación 178/243...\n",
      "Combinación 179/243...\n",
      "Combinación 180/243...\n",
      "Combinación 181/243...\n",
      "Combinación 182/243...\n",
      "Combinación 183/243...\n",
      "Combinación 184/243...\n",
      "Combinación 185/243...\n",
      "Combinación 186/243...\n",
      "Combinación 187/243...\n",
      "Combinación 188/243...\n",
      "Combinación 189/243...\n",
      "Combinación 190/243...\n",
      "Combinación 191/243...\n",
      "Combinación 192/243...\n",
      "Combinación 193/243...\n",
      "Combinación 194/243...\n",
      "Combinación 195/243...\n",
      "Combinación 196/243...\n",
      "Combinación 197/243...\n",
      "Combinación 198/243...\n",
      "Combinación 199/243...\n",
      "Combinación 200/243...\n",
      "Combinación 201/243...\n",
      "Combinación 202/243...\n",
      "Combinación 203/243...\n",
      "Combinación 204/243...\n",
      "Combinación 205/243...\n",
      "Combinación 206/243...\n",
      "Combinación 207/243...\n",
      "Combinación 208/243...\n",
      "Combinación 209/243...\n",
      "Combinación 210/243...\n",
      "Combinación 211/243...\n",
      "Combinación 212/243...\n",
      "Combinación 213/243...\n",
      "Combinación 214/243...\n",
      "Combinación 215/243...\n",
      "Combinación 216/243...\n",
      "Combinación 217/243...\n",
      "Combinación 218/243...\n",
      "Combinación 219/243...\n",
      "Combinación 220/243...\n",
      "Combinación 221/243...\n",
      "Combinación 222/243...\n",
      "Combinación 223/243...\n",
      "Combinación 224/243...\n",
      "Combinación 225/243...\n",
      "Combinación 226/243...\n",
      "Combinación 227/243...\n",
      "Combinación 228/243...\n",
      "Combinación 229/243...\n",
      "Combinación 230/243...\n",
      "Combinación 231/243...\n",
      "Combinación 232/243...\n",
      "Combinación 233/243...\n",
      "Combinación 234/243...\n",
      "Combinación 235/243...\n",
      "Combinación 236/243...\n",
      "Combinación 237/243...\n",
      "Combinación 238/243...\n",
      "Combinación 239/243...\n",
      "Combinación 240/243...\n",
      "Combinación 241/243...\n",
      "Combinación 242/243...\n",
      "Combinación 243/243...\n",
      "Mejores hiper-parámetros: {'colsample_bytree': 0.7, 'eta': 0.4, 'gamma': 0.2, 'lambda': 2, 'max_depth': 4}\n",
      "Mejor exactitud: 91.0%\n"
     ]
    }
   ],
   "source": [
    "# Realizar afinación con la función anterior\n",
    "# Crear grilla de hiper-parámetros\n",
    "grilla_hparams = {\n",
    "    'eta': [0.4, 0.5, 0.6],     # Tasas de aprendizaje\n",
    "    'gamma': [0, 0.1, 0.2],     # Hiper-parámetro 𝜸\n",
    "    'lambda': [1.5, 2, 2.5],    # Hiper-parámetro λ\n",
    "    'max_depth': [2, 3, 4],     # Máxima profundidad del árbol\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9], # Porcentaje de muestreo de las columnas\n",
    "}\n",
    "\n",
    "# Parámetros que no se ajustarán\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 42,   \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "best_score, best_params = afinar_hiperparams_clf(dtrain, grilla_hparams, params, custom_metrics_clf)\n",
    "\n",
    "# Imprimir mejores hiper-parámetros y mejor puntaje\n",
    "print(\"Mejores hiper-parámetros:\", best_params)\n",
    "print(\"Mejor exactitud:\", f'{100*best_score:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora estimaremos el desempeño del modelo afinado tanto para entrenamiento como para prueba usando la función para realizar la validación cruzada. En este caso usaremos como parámetros tanto los parámetros que no se afinan como los mejores hiper-parámetros que acabamos de encontrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESEMPEÑO MODELO AFINADO - VALIDACIÓN CRUZADA: \n",
      "==================================================\n",
      "   Exactitud train: 94.6%\n",
      "   Exactitud test: 91.0%\n"
     ]
    }
   ],
   "source": [
    "# Mostrar desempeño del modelo afinado\n",
    "\n",
    "# Modelo afinado\n",
    "parametros = best_params | params\n",
    "\n",
    "# CV personalizada\n",
    "cv_res = cv_clf_personalizada(dtrain, custom_metrics_clf, params = parametros)\n",
    "\n",
    "# Imprimir en pantalla\n",
    "best_round = cv_res['test-exactitud-mean'].idxmax()\n",
    "clf_afinado_train = cv_res['train-exactitud-mean'].iloc[best_round]\n",
    "clf_afinado_test = cv_res['test-exactitud-mean'].iloc[best_round]\n",
    "\n",
    "print('DESEMPEÑO MODELO AFINADO - VALIDACIÓN CRUZADA: ')\n",
    "print('='*50)\n",
    "print(f'   Exactitud train: {100*clf_afinado_train:.1f}%')\n",
    "print(f'   Exactitud test: {100*clf_afinado_test:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y hemos logrado pasar de un modelo con desempeño entrenamiento/prueba 92.8%/90.4% a uno con desempeño de 94.6%/91.0%.\n",
    "\n",
    "Aunque esta afinación ha incrementado el desempeño con los datos de prueba también ha incrementado ligeramente el \"overfitting\" y esto se podría mejorar probando con una grilla hiper-parámetros más amplia.\n",
    "\n",
    "Sin embargo, también debemos tener en cuenta que el incremento en el desempeño (90.4% a 91.0%) ha sido marginal y esto muestra que XGBoost es realmente un modelo robusto y que, generalmente, las mejoras tras la afinación de hiper-parámetros serán marginales.\n",
    "\n",
    "Por último, podemos entrenar el modelo afinado y generar predicciones con datos totalmente nuevos (el set de prueba, que no hemos usado hasta el momento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar modelo afinado\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = parametros | {'enable_categorical':True}\n",
    "clf_afinado = XGBClassifier(**params)\n",
    "clf_afinado.fit(x_tr,y_tr) # Se recomienda agregar early stopping\n",
    "\n",
    "# Y generar predicciones sobre datos nuevos\n",
    "preds = clf_afinado.predict(x_ts)\n",
    "preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
