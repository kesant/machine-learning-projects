{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66b95c-321e-435f-a440-8f9f0e9e0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import IForest from pyod\n",
    "from pyod.models.iforest import IForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ceed86-e6ab-4919-8cf3-0569b3515fd3",
   "metadata": {},
   "source": [
    "# Detecting outliers with IForest\n",
    "IForest is a robust estimator and only requires a few lines of code to detect outliers from any dataset. You may find that this syntax looks familiar since it closely resembles sklearn syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355455a0-a67a-4ed9-8f8d-19fe886c351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance with default parameters\n",
    "iforest = IForest()\n",
    "\n",
    "# Generate outlier labels\n",
    "labels = iforest.fit_predict(big_mart)\n",
    "\n",
    "# Filter big_mart for outliers\n",
    "outliers = big_mart[labels==1]\n",
    "\n",
    "print(outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaa2b3-a583-4b7b-be33-ebf04cdf45cf",
   "metadata": {},
   "source": [
    "# Choosing contamination\r\n",
    "Even though the code implementation only takes a few lines, finding the suitable contamination requires attention.\r\n",
    "\r\n",
    "Recall that contamination parameter only affects the results of IForst. Once IForest generates raw anomaly scores, contamination is used to chose the top n% of anomaly scores as outliers. For example, 5% contamination will choose the observations with the highest 5% of anomaly scores as outliers.\r\n",
    "\r\n",
    "Although we will discuss some tuning methods in the following video, for now, you will practice setting an arbitrary value to the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513390d-3e5b-4d79-9950-a663f0fb19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an instance with 5% contamination\n",
    "iforest = IForest(contamination=0.05)\n",
    "\n",
    "# Fit IForest to Big Mart sales data\n",
    "iforest.fit(big_mart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7ec77-8752-40a8-a95a-1b1a79ab9627",
   "metadata": {},
   "source": [
    "# Choosing n_estimators\r\n",
    "n_estimators is the parameter that influences model performance the most. Building IForest with enough trees ensures that the algorithm has enough generalization power to isolate the outliers from normal data points. The optimal number of trees depends on dataset size, and any number that is too high or too low will lead to inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396cded-9911-4fac-be1d-7cb5ff78165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an IForest with 300 trees\n",
    "iforest = IForest(n_estimators=300)\n",
    "\n",
    "# Fit to the Big Mart sales data\n",
    "iforest.fit(big_mart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d5c69-60b8-4a32-b7b7-a403e4525d8e",
   "metadata": {},
   "source": [
    "# Tuning contamination\r\n",
    "Finally, it is time to tune the notorious contamination parameter. The evaluate_outlier_classifier and evaluate_regressor functions from the video are already loaded for you. You can inspect them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a71244-6d97-4396-b1c5-f4503f5f2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_outlier_classifier(model, data):\n",
    "    # Get labels\n",
    "    labels = model.fit_predict(data)\n",
    "\n",
    "    # Return inliers\n",
    "    return data[labels == 0]\n",
    "def evaluate_regressor(inliers):\n",
    "    X = inliers.drop(\"price\", axis=1)\n",
    "    y = inliers[['price']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    preds = lr.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    return round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068f49b-b867-45c4-8a21-3814bdf65c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of contaminations and an empty dictionary\n",
    "contaminations = [0.07, 0.1, 0.15, 0.25]\n",
    "scores = dict()\n",
    "\n",
    "for c in contaminations:\n",
    "    # Instantiate IForest with the current c\n",
    "    iforest = IForest(contamination=c, random_state=10)\n",
    "    \n",
    "    # Get inliers with the current IForest\n",
    "    inliers = evaluate_outlier_classifier(iforest, airbnb_df)\n",
    "    \n",
    "    # Calculate and store RMSE into scores\n",
    "    scores[c]= evaluate_regressor(inliers)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315416e8-e668-4f4b-89c0-435177b664e2",
   "metadata": {},
   "source": [
    "# Tuning multiple hyperparameters\n",
    "In this exercise, you will practice tuning multiple hyperparameters simultaneously. This is a valuable topic to learn, as hyperparameters of an algorithm usually affect each other's values. Therefore, tuning them individually is not usually the recommended course of action.\n",
    "\n",
    "You will tune the max_features and max_samples parameters of IForest using a sample of the Big Mart sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c9001-b4e7-4110-b624-990d819789d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = [0.6, 0.8, 1]\n",
    "max_samples = [0.8, 0.9, 1]\n",
    "scores = dict()\n",
    "\n",
    "for mf, ms in product(max_features, max_samples):\n",
    "    # Instantiate an IForest\n",
    "    iforest = IForest(max_features=mf, max_samples=ms, n_jobs=-1, contamination=.25, random_state=1)\n",
    "    \n",
    "    # Get the inliers with the current IForest\n",
    "    inliers = evaluate_outlier_classifier(iforest, airbnb_df)\n",
    "    \n",
    "    # Calculate and store RMSE into scores\n",
    "    scores[(mf,ms)] = evaluate_regressor(inliers)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b76ef-9109-4947-96b8-45d92bc593ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce171343-13cf-4b51-932a-35706a51a0a1",
   "metadata": {},
   "source": [
    "# Alternative way of classifying with IForest\n",
    "Until now, you have been using the .fit_predict() method to fit IForest and generate predictions simultaneously. However, pyod documentation suggests using the fit function first and accessing the inlier/outlier labels_ via a handy attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63e1f7-0598-4d0f-b58f-35486eed83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IForest(n_estimators=200)\n",
    "\n",
    "# Fit (only fit) it to the Big Mart sales\n",
    "iforest.fit(big_mart)\n",
    "\n",
    "# Access the labels_ for the data\n",
    "labels = iforest.labels_\n",
    "\n",
    "# Filter outliers from big_mart\n",
    "outliers = big_mart[labels==1]\n",
    "\n",
    "print(len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2cd3f-9775-4f1c-8523-a305847feb1a",
   "metadata": {},
   "source": [
    "# Using outlier probabilities\r\n",
    "An alternative to isolating outliers with contamination is using outlier probabilities. The best thing about this method is that you can choose an arbitrary probability threshold, which means you can be as confident as you want in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ab673-3f6a-46f3-acb3-5c06a64de0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IForest(random_state=10).fit(big_mart)\n",
    "\n",
    "# Calculate probabilities\n",
    "probs = iforest.predict_proba(big_mart)\n",
    "\n",
    "# Extract the probabilities for outliers\n",
    "outlier_probs = probs[:,1]\n",
    "\n",
    "# Filter for when the probability is higher than 70%\n",
    "outliers = big_mart[outlier_probs>0.70]\n",
    "\n",
    "print(len(outliers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
